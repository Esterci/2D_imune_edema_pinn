{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definições iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size x = 11, y = 11 \n",
      " \n",
      "Steps in time = 101\n",
      "Steps in space_x = 11\n",
      "Steps in space_y = 11\n",
      "\n",
      "CFL:  0.0004999999999999999 \n",
      "\n",
      "struct_name:  h--0.1__k--0.1__Db--0.0001__Dn--0.0001__phi--0.2__ksi--0.0__cb--0.15__lambd_nb--1.8__mi_n--0.2__lambd_bn--0.1__y_n--0.1__Cn_max--0.5__X_nb--0.0001__x_dom_min--0__x_dom_max--1__y_dom_min--0__y_dom_max--1__t_dom_min--0__t_dom_max--10\n"
     ]
    }
   ],
   "source": [
    "h = 0.1\n",
    "k = 0.1\n",
    "Db = 0.0001\n",
    "Dn = 0.0001\n",
    "phi = 0.2\n",
    "ksi = 0.0\n",
    "cb = 0.15\n",
    "lambd_nb = 1.8\n",
    "mi_n = 0.2\n",
    "lambd_bn = 0.1\n",
    "y_n = 0.1\n",
    "Cn_max = 0.5\n",
    "X_nb = 1e-4\n",
    "x_dom = (0, 1)\n",
    "y_dom = (0, 1)\n",
    "t_dom = (0, 10)\n",
    "\n",
    "size_x = int(((x_dom[1] - x_dom[0]) / (h))) + 1\n",
    "size_y = int(((y_dom[1] - y_dom[0]) / (h))) + 1\n",
    "size_t = int(((t_dom[1] - t_dom[0]) / (k))) + 1\n",
    "\n",
    "print(\"Size x = {:d}, y = {:d} \\n \".format(size_x, size_y))\n",
    "\n",
    "print(\n",
    "    \"Steps in time = {:d}\\nSteps in space_x = {:d}\\nSteps in space_y = {:d}\\n\".format(\n",
    "        size_t,\n",
    "        size_x,\n",
    "        size_y,\n",
    "    )\n",
    ")\n",
    "\n",
    "CFL = (Db * k) / ((2 * (h * h)))\n",
    "\n",
    "print(\"CFL: \", CFL, \"\\n\")\n",
    "\n",
    "if CFL >= 1:\n",
    "    print(\"Criterio CFL não satisfeito\\n\")\n",
    "\n",
    "# Computing FDM model\n",
    "\n",
    "struct_name = (\n",
    "    \"h--\"\n",
    "    + str(h)\n",
    "    + \"__k--\"\n",
    "    + str(k)\n",
    "    + \"__Db--\"\n",
    "    + str(Db)\n",
    "    + \"__Dn--\"\n",
    "    + str(Dn)\n",
    "    + \"__phi--\"\n",
    "    + str(phi)\n",
    "    + \"__ksi--\"\n",
    "    + str(ksi)\n",
    "    + \"__cb--\"\n",
    "    + str(cb)\n",
    "    + \"__lambd_nb--\"\n",
    "    + str(lambd_nb)\n",
    "    + \"__mi_n--\"\n",
    "    + str(mi_n)\n",
    "    + \"__lambd_bn--\"\n",
    "    + str(lambd_bn)\n",
    "    + \"__y_n--\"\n",
    "    + str(y_n)\n",
    "    + \"__Cn_max--\"\n",
    "    + str(Cn_max)\n",
    "    + \"__X_nb--\"\n",
    "    + str(X_nb)\n",
    "    + \"__x_dom_min--\"\n",
    "    + str(x_dom[0])\n",
    "    + \"__x_dom_max--\"\n",
    "    + str(x_dom[-1])\n",
    "    + \"__y_dom_min--\"\n",
    "    + str(y_dom[0])\n",
    "    + \"__y_dom_max--\"\n",
    "    + str(y_dom[-1])\n",
    "    + \"__t_dom_min--\"\n",
    "    + str(t_dom[0])\n",
    "    + \"__t_dom_max--\"\n",
    "    + str(t_dom[-1])\n",
    ")\n",
    "print(\"struct_name: \", struct_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de nullclines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "with open(\"fdm_sim/Cp__\" + struct_name + \".pkl\", \"rb\") as f:\n",
    "    Cb_fdm = pk.load(f)\n",
    "\n",
    "with open(\"fdm_sim/Cl__\" + struct_name + \".pkl\", \"rb\") as f:\n",
    "    Cn_fdm = pk.load(f)\n",
    "\n",
    "t_np = np.linspace(t_dom[0], t_dom[-1], num=size_t, endpoint=True,dtype=np.float32)\n",
    "x_np = np.linspace(x_dom[0], x_dom[-1], num=size_t, endpoint=True,dtype=np.float32)\n",
    "y_np = np.linspace(y_dom[0], y_dom[-1], num=size_t, endpoint=True,dtype=np.float32)\n",
    "\n",
    "\n",
    "tt, xx, yy = np.meshgrid(t_np, x_np, y_np,)\n",
    "\n",
    "data_input_np = np.array([Cn_fdm.flatten(), Cb_fdm.flatten()]).T\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    t_tc = (\n",
    "        torch.tensor(tt, dtype=torch.float32, requires_grad=True)\n",
    "        .reshape(-1, 1)\n",
    "        .to(device)\n",
    "    )\n",
    "    x_tc = (\n",
    "        torch.tensor(xx, dtype=torch.float32, requires_grad=True)\n",
    "        .reshape(-1, 1)\n",
    "        .to(device)\n",
    "    )\n",
    "    y_tc = (\n",
    "        torch.tensor(yy, dtype=torch.float32, requires_grad=True)\n",
    "        .reshape(-1, 1)\n",
    "        .to(device)\n",
    "    )\n",
    "    data_input = torch.tensor(data_input_np, dtype=torch.float32).to(device)\n",
    "\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    t_tc = torch.tensor(tt, dtype=torch.float32, requires_grad=True).reshape(-1, 1)\n",
    "    x_tc = torch.tensor(xx, dtype=torch.float32, requires_grad=True).reshape(-1, 1)\n",
    "    y_tc = torch.tensor(yy, dtype=torch.float32, requires_grad=True).reshape(-1, 1)\n",
    "    data_input = torch.tensor(data_input_np, dtype=torch.float32)\n",
    "\n",
    "print(device)\n",
    "\n",
    "del xx\n",
    "del yy\n",
    "del tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_dict = {\n",
    "    \"Elu\": nn.ELU,\n",
    "    \"LeakyReLU\": nn.LeakyReLU,\n",
    "    \"Sigmoid\": nn.Sigmoid,\n",
    "    \"Softplus\": nn.Softplus,\n",
    "    \"Tanh\": nn.Tanh,\n",
    "    \"Linear\": nn.Linear,\n",
    "    \"ReLU\": nn.ReLU,\n",
    "    \"RReLU\": nn.RReLU,\n",
    "    \"SELU\": nn.SELU,\n",
    "    \"CELU\": nn.CELU,\n",
    "    \"GELU\": nn.GELU,\n",
    "    \"SiLU\": nn.SiLU,\n",
    "    \"GLU\": nn.GLU,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_str = \"Tanh--32__Tanh--32__Tanh--32__GELU--32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(arch_str):\n",
    "    hidden_layers = arch_str.split(\"__\")\n",
    "\n",
    "    modules = []\n",
    "\n",
    "    for params in hidden_layers:\n",
    "        if len(params) != 0:\n",
    "            activation, out_neurons = params.split(\"--\")\n",
    "\n",
    "            if len(modules) == 0:\n",
    "                if activation == \"Linear\":\n",
    "                    modules.append(activation_dict[activation](3, int(out_neurons)))\n",
    "\n",
    "                else:\n",
    "                    modules.append(nn.Linear(3, int(out_neurons)))\n",
    "                    modules.append(activation_dict[activation]())\n",
    "\n",
    "            else:\n",
    "                if activation == \"Linear\":\n",
    "                    modules.append(\n",
    "                        activation_dict[activation](int(in_neurons), int(out_neurons))\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    modules.append(nn.Linear(int(in_neurons), int(out_neurons)))\n",
    "                    modules.append(activation_dict[activation]())\n",
    "\n",
    "            in_neurons = out_neurons\n",
    "\n",
    "    modules.append(nn.Linear(int(in_neurons), 2))\n",
    "\n",
    "    return nn.Sequential(*modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3, out_features=32, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (5): Tanh()\n",
      "  (6): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (7): GELU(approximate='none')\n",
      "  (8): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = generate_model(arch_str).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_torch(dataset):\n",
    "    with torch.no_grad():\n",
    "        dt_min = torch.min(dataset, 0).values\n",
    "        dt_max = torch.max(dataset, 0).values\n",
    "        normalized = (dataset - dt_min) / (dt_max - dt_min)\n",
    "\n",
    "    return normalized.requires_grad_(True), dt_min, dt_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data_input(data_input, steps):\n",
    "    with torch.no_grad():\n",
    "        dataset = data_input.reshape(steps, steps, 2)\n",
    "        normalized = torch.zeros_like(dataset)\n",
    "        for i in range(len(dataset)):\n",
    "            dt_min = torch.min(dataset[i], 0).values\n",
    "            dt_max = torch.max(dataset[i], 0).values\n",
    "            normalized[i] = (dataset[i] - dt_min) / (dt_max - dt_min)\n",
    "\n",
    "    return normalized.reshape((steps) * (steps), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(dataset, dt_min, dt_max):\n",
    "    return (dt_max - dt_min) * dataset + dt_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(x, y, z):\n",
    "    Data_num = np.arange(x.shape[0])\n",
    "    np.random.shuffle(Data_num)\n",
    "\n",
    "    return x[Data_num], y[Data_num], z[Data_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x, y, z, test_size=0.5, shuffle=True):\n",
    "    with torch.no_grad():\n",
    "        if shuffle:\n",
    "            x, y, z = shuffle_data(x, y, z)\n",
    "        if test_size < 1:\n",
    "            train_ratio = len(x) - int(len(x) * test_size)\n",
    "            x_train, x_test = x[:train_ratio], x[train_ratio:]\n",
    "            y_train, y_test = y[:train_ratio], y[train_ratio:]\n",
    "            z_train, z_test = z[:train_ratio], z[train_ratio:]\n",
    "            return (\n",
    "                x_train.requires_grad_(True),\n",
    "                x_test.requires_grad_(True),\n",
    "                y_train.requires_grad_(True),\n",
    "                y_test.requires_grad_(True),\n",
    "                z_train.requires_grad_(True),\n",
    "                z_test.requires_grad_(True),\n",
    "            )\n",
    "        elif test_size in range(1, len(x)):\n",
    "            x_train, x_test = x[test_size:], x[:test_size]\n",
    "            y_train, y_test = y[test_size:], y[:test_size]\n",
    "            z_train, z_test = z[test_size:], z[:test_size]\n",
    "            return (\n",
    "                x_train.requires_grad_(True),\n",
    "                x_test.requires_grad_(True),\n",
    "                y_train.requires_grad_(True),\n",
    "                y_test.requires_grad_(True),\n",
    "                z_train.requires_grad_(True),\n",
    "                z_test.requires_grad_(True),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerenate_training_points(num_points, device):\n",
    "    x = torch.rand(num_points, 1).to(device)\n",
    "    y = torch.rand(num_points, 1).to(device)\n",
    "    t = torch.rand(num_points, 1).to(device) * 10\n",
    "\n",
    "    return x.requires_grad_(True), y.requires_grad_(True), t.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerenate_boundary_points(num_points, device):\n",
    "    x_boundary = torch.tensor([0.0, 1.0]).repeat(num_points // 2)\n",
    "    y_boundary = torch.rand(num_points)\n",
    "\n",
    "    if torch.rand(1) > 0.5:\n",
    "        x_boundary, y_boundary = y_boundary, x_boundary\n",
    "        n = torch.tensor([[0.0, -1.0], [0.0, 1.0]]).repeat(num_points // 2, 1)\n",
    "    else:\n",
    "        n = torch.tensor([[-1.0, 0.0], [1.0, 0.0]]).repeat(num_points // 2, 1)\n",
    "\n",
    "    return (\n",
    "        x_boundary.to(device).requires_grad_(True).view(-1,1),\n",
    "        y_boundary.to(device).requires_grad_(True).view(-1,1),\n",
    "        n.to(device),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_condition(x, y):\n",
    "\n",
    "    Cl = torch.full_like(x, 0)\n",
    "\n",
    "    Cp = torch.full_like(x, 0)\n",
    "\n",
    "    for i, (xx, yy) in enumerate(zip(x, y)):\n",
    "        if ((xx >= 0.5) and (xx <= 0.6)) and ((yy >= 0.5) and (yy <= 0.6)):\n",
    "            Cp[i] = 0.2\n",
    "\n",
    "    return torch.cat([Cl, Cp], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_condition(x_b, y_b, t_b, n, model, Dn, X_nb, Db):\n",
    "    \n",
    "    input_data = torch.cat([x_b, y_b, t_b], dim=1)\n",
    "\n",
    "    Cp, Cl = model(input_data).tensor_split(2, dim=1)\n",
    "\n",
    "    nx, ny = n.tensor_split(2, dim=1)\n",
    "\n",
    "    if nx[0].item() != 0:\n",
    "        dCp_dx = torch.autograd.grad(\n",
    "            Cp,\n",
    "            x_b,\n",
    "            grad_outputs=torch.ones_like(Cp),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )\n",
    "\n",
    "        dCl_dx = torch.autograd.grad(\n",
    "            Cl,\n",
    "            x_b,\n",
    "            grad_outputs=torch.ones_like(Cl),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )\n",
    "\n",
    "        Cl_boundary = torch.mul(\n",
    "            ((Dn * dCl_dx[0]) - X_nb * torch.mul(Cl, dCp_dx[0])), nx\n",
    "        )\n",
    "\n",
    "        Cp_boundary = torch.mul((Db * dCp_dx[0]), nx)\n",
    "\n",
    "        return torch.cat([Cl_boundary, Cp_boundary], dim=1)\n",
    "\n",
    "    else:\n",
    "        dCp_dy = torch.autograd.grad(\n",
    "            Cp,\n",
    "            y_b,\n",
    "            grad_outputs=torch.ones_like(Cp),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )\n",
    "\n",
    "        dCl_dy = torch.autograd.grad(\n",
    "            Cl,\n",
    "            y_b,\n",
    "            grad_outputs=torch.ones_like(Cl),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )\n",
    "\n",
    "        Cl_boundary = torch.mul(\n",
    "            ((Dn * dCl_dy[0]) - X_nb * torch.mul(Cl, dCp_dy[0])), ny\n",
    "        )\n",
    "\n",
    "        Cp_boundary = torch.mul((Db * dCp_dy[0]), ny)\n",
    "\n",
    "        return torch.cat([Cl_boundary, Cp_boundary], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde(model, x, y, t, cb, lambd_nb, Db, y_n, Cn_max, lambd_bn, mi_n, Dn, X_nb):\n",
    "    input_data = torch.cat([x, y, t], dim=1)\n",
    "\n",
    "    Cl, Cp = model(input_data).tensor_split(2, dim=1)\n",
    "\n",
    "    # Calculating Cp value\n",
    "\n",
    "    dCp_dx, dCp_dy = torch.autograd.grad(\n",
    "        Cp,\n",
    "        [x, y],\n",
    "        grad_outputs=torch.ones_like(Cp),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )\n",
    "\n",
    "    dCp_dx_2 = torch.autograd.grad(\n",
    "        dCp_dx,\n",
    "        x,\n",
    "        grad_outputs=torch.ones_like(dCp_dx),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    dCp_dy_2 = torch.autograd.grad(\n",
    "        dCp_dy,\n",
    "        y,\n",
    "        grad_outputs=torch.ones_like(dCp_dy),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    dCp_dt = torch.autograd.grad(\n",
    "        Cp,\n",
    "        t,\n",
    "        grad_outputs=torch.ones_like(Cp),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    qb = cb * Cp\n",
    "    rb = lambd_nb * torch.mul(Cl, Cp)\n",
    "\n",
    "    Cp_eq = Db * (dCp_dx_2 + dCp_dy_2) - rb + qb - dCp_dt\n",
    "\n",
    "    # Calculating Cl value\n",
    "\n",
    "    dCl_dx, dCl_dy = torch.autograd.grad(\n",
    "        Cl,\n",
    "        [x, y],\n",
    "        grad_outputs=torch.ones_like(Cl),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )\n",
    "\n",
    "    dCl_dx_2 = torch.autograd.grad(\n",
    "        dCl_dx,\n",
    "        x,\n",
    "        grad_outputs=torch.ones_like(dCl_dx),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    dCl_dy_2 = torch.autograd.grad(\n",
    "        dCl_dy,\n",
    "        y,\n",
    "        grad_outputs=torch.ones_like(dCl_dy),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    dCl_dt = torch.autograd.grad(\n",
    "        Cl,\n",
    "        t,\n",
    "        grad_outputs=torch.ones_like(Cl),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    qn = y_n * torch.mul(Cp, (Cn_max - Cl))\n",
    "    rn = lambd_bn * torch.mul(Cl, Cp) + mi_n * Cl\n",
    "\n",
    "    Cl_eq = (\n",
    "        Dn * (dCl_dx_2 + dCl_dy_2)\n",
    "        - X_nb\n",
    "        * (\n",
    "            (torch.mul(dCl_dx, dCp_dx) + torch.mul(Cl, dCp_dx_2))\n",
    "            + (torch.mul(dCl_dy, dCp_dy) + torch.mul(Cl, dCp_dy_2))\n",
    "        )\n",
    "        - rn\n",
    "        + qn\n",
    "    ) - dCl_dt\n",
    "\n",
    "    return torch.cat([Cl_eq, Cp_eq], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    n_epochs,\n",
    "    batch_size,\n",
    "    decay_rate,\n",
    "    model,\n",
    "    device,\n",
    "    data_input,\n",
    "    x,\n",
    "    y,\n",
    "    t,\n",
    "    n_points,\n",
    "    constant_properties,\n",
    "    norm_weights=None,\n",
    "    validation=None,\n",
    "):\n",
    "    dt_min, dt_max = norm_weights if norm_weights else (0, 1)\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    lr_scheduler = optim.lr_scheduler.ExponentialLR(\n",
    "        optimizer=optimizer, gamma=decay_rate\n",
    "    )\n",
    "\n",
    "    if validation:\n",
    "        train_data, test_data, train_t, test_t, train_dom, test_dom = train_test_split(\n",
    "            data_input, t, torch.cat([x, y], dim=1), test_size=validation\n",
    "        )\n",
    "        train_x, train_y = train_dom.split(1, dim=1)\n",
    "        test_x, test_y = test_dom.split(1, dim=1)\n",
    "        train_data_input = torch.cat([train_x, train_y, train_t], dim=1)\n",
    "        test_data_input = torch.cat([test_x, test_y, test_t], dim=1)\n",
    "\n",
    "    else:\n",
    "        train_data = data_input\n",
    "        test_data = None\n",
    "        train_data_input = torch.cat([t, train_x, train_y], dim=1)\n",
    "        test_data_input = None\n",
    "        train_t = t\n",
    "        test_t = None\n",
    "        train_x = x\n",
    "        test_x = None\n",
    "        train_y = y\n",
    "        test_y = None\n",
    "\n",
    "    C_pde_loss_it = torch.zeros(n_epochs).to(device)\n",
    "    C_data_loss_it = torch.zeros(n_epochs).to(device)\n",
    "    C_boundary_loss_it = torch.zeros(n_epochs).to(device)\n",
    "    C_initial_loss_it = torch.zeros(n_epochs).to(device)\n",
    "    C_initial = initial_condition(train_x, train_y).to(device)\n",
    "    val_loss_it = torch.zeros(n_epochs).to(device)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(0, len(train_t), batch_size):\n",
    "\n",
    "            # Computing intial loss\n",
    "            t_initial = torch.zeros_like(train_t[i : i + batch_size])\n",
    "\n",
    "            mesh_ini = torch.cat(\n",
    "                [train_x[i : i + batch_size], train_y[i : i + batch_size], t_initial],\n",
    "                dim=1,\n",
    "            )\n",
    "\n",
    "            C_initial_pred = model(mesh_ini)\n",
    "\n",
    "            loss_initial = loss_fn(C_initial[i : i + batch_size], C_initial_pred)\n",
    "\n",
    "            # Computing pde loss\n",
    "\n",
    "            x_pde, y_pde, t_pde = gerenate_training_points(n_points, device)\n",
    "\n",
    "            predicted_pde = pde(\n",
    "                model,\n",
    "                x_pde,\n",
    "                y_pde,\n",
    "                t_pde,\n",
    "                constant_properties[\"cb\"],\n",
    "                constant_properties[\"lambd_nb\"],\n",
    "                constant_properties[\"Db\"],\n",
    "                constant_properties[\"y_n\"],\n",
    "                constant_properties[\"Cn_max\"],\n",
    "                constant_properties[\"lambd_bn\"],\n",
    "                constant_properties[\"mi_n\"],\n",
    "                constant_properties[\"Dn\"],\n",
    "                constant_properties[\"X_nb\"],\n",
    "            )\n",
    "\n",
    "            loss_pde = loss_fn(\n",
    "                predicted_pde,\n",
    "                torch.zeros_like(predicted_pde),\n",
    "            )\n",
    "\n",
    "            # Computing boundary loss\n",
    "\n",
    "            x_bnd, y_bnd, n_bnd = gerenate_boundary_points(n_points, device)\n",
    "\n",
    "            predicted_boundary = boundary_condition(\n",
    "                x_bnd,\n",
    "                y_bnd,\n",
    "                t_pde,\n",
    "                n_bnd,\n",
    "                model,\n",
    "                constant_properties[\"Dn\"],\n",
    "                constant_properties[\"X_nb\"],\n",
    "                constant_properties[\"Db\"],\n",
    "            )\n",
    "\n",
    "            loss_boundary = loss_fn(\n",
    "                predicted_boundary,\n",
    "                torch.zeros_like(predicted_boundary),\n",
    "            )\n",
    "\n",
    "            # Computing data loss\n",
    "\n",
    "            C_pred = model(train_data_input[i : i + batch_size])\n",
    "\n",
    "            loss_data = loss_fn(train_data[i : i + batch_size], C_pred)\n",
    "\n",
    "            # Computing validation loss\n",
    "\n",
    "            if validation:\n",
    "                with torch.no_grad():\n",
    "                    val_loss = loss_fn(test_data, model(test_data_input))\n",
    "\n",
    "            loss = loss_initial + loss_pde + loss_boundary + loss_data * 10\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        C_pde_loss_it[epoch] = loss_pde.item()\n",
    "        C_boundary_loss_it[epoch] = loss_boundary.item()\n",
    "        C_initial_loss_it[epoch] = loss_initial.item()\n",
    "        C_data_loss_it[epoch] = loss_data.item()\n",
    "        val_loss_it[epoch] = val_loss.item() if validation else 0\n",
    "\n",
    "        if (epoch % 100) == 0:\n",
    "            print(\n",
    "                f\"Finished epoch {epoch+1}, latest loss {loss}, validation loss {val_loss.item()}\"\n",
    "                if validation\n",
    "                else f\"Finished epoch {epoch+1}, latest loss {loss}\"\n",
    "            )\n",
    "\n",
    "    return (\n",
    "        model,\n",
    "        C_pde_loss_it,\n",
    "        C_boundary_loss_it,\n",
    "        C_initial_loss_it,\n",
    "        C_data_loss_it,\n",
    "        val_loss_it,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 1, latest loss 0.0879838615655899, validation loss 0.008482404053211212\n"
     ]
    }
   ],
   "source": [
    "decay_rate = 0.999\n",
    "n_epochs = 300\n",
    "batch_size = 156\n",
    "\n",
    "constant_properties = {\n",
    "    \"h\": h,\n",
    "    \"k\": k,\n",
    "    \"Db\": Db,\n",
    "    \"Dn\": Dn,\n",
    "    \"phi\": phi,\n",
    "    \"ksi\": ksi,\n",
    "    \"cb\": cb,\n",
    "    \"lambd_nb\": lambd_nb,\n",
    "    \"mi_n\": mi_n,\n",
    "    \"lambd_bn\": lambd_bn,\n",
    "    \"y_n\": y_n,\n",
    "    \"Cn_max\": Cn_max,\n",
    "    \"X_nb\": X_nb,\n",
    "}\n",
    "\n",
    "model, C_pde_loss_it, C_boundary_loss_it, C_initial_loss_it, C_data_loss_it, val_loss_it = train(\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    decay_rate=decay_rate,\n",
    "    model=model,\n",
    "    device=device,\n",
    "    data_input=data_input,\n",
    "    x=x_tc,\n",
    "    y=y_tc,\n",
    "    t=t_tc,\n",
    "    n_points=batch_size,\n",
    "    constant_properties=constant_properties,\n",
    "    validation=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=[18, 9])\n",
    "\n",
    "fig.suptitle(\"Curva de aprendizagem\", fontsize=16)\n",
    "\n",
    "# Plotango 3D\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.set_xlabel(\"iterações\")\n",
    "ax.set_ylabel(\"perda\")\n",
    "ax.plot(\n",
    "    range(len(C_pde_loss_it.cpu().numpy())),\n",
    "    C_pde_loss_it.cpu().numpy(),\n",
    "    label=\"PDE loss\",\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    range(len(C_boundary_loss_it.cpu().numpy())),\n",
    "    C_pde_loss_it.cpu().numpy(),\n",
    "    label=\"Boundary loss\",\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    range(len(val_loss_it.cpu().numpy())),\n",
    "    C_pde_loss_it.cpu().numpy(),\n",
    "    label=\"Validation loss\",\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    range(len(C_data_loss_it.cpu().numpy())),\n",
    "    C_data_loss_it.cpu().numpy(),\n",
    "    label=\"Data loss\",\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    range(len(C_initial_loss_it.cpu().numpy())),\n",
    "    C_initial_loss_it.cpu().numpy(),\n",
    "    label=\"Initial loss\",\n",
    ")\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=[18, 9])\n",
    "\n",
    "fig.suptitle(\"Curva de aprendizagem\", fontsize=16)\n",
    "\n",
    "# Plotango 3D\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.set_xlabel(\"iterações\")\n",
    "ax.set_ylabel(\"perda\")\n",
    "\n",
    "ax.plot(\n",
    "    range(len(C_initial_loss_it.cpu().numpy())),\n",
    "    C_initial_loss_it.cpu().numpy()\n",
    "    + C_pde_loss_it.cpu().numpy()\n",
    "    + C_boundary_loss_it.cpu().numpy()\n",
    "    + C_data_loss_it.cpu().numpy(),\n",
    "    label=\"PINN loss\",\n",
    ")\n",
    "ax.plot(\n",
    "    range(len(val_loss_it.cpu().numpy())),\n",
    "    val_loss_it.cpu().numpy(),\n",
    "    label=\"Validation loss\",\n",
    ")\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fdm_sim/time__\" + struct_name + \".pkl\", \"rb\") as f:\n",
    "    time_fdm = pk.load(f)\n",
    "    \n",
    "model_cpu = model.to(\"cpu\")\n",
    "\n",
    "speed_up = []\n",
    "\n",
    "mesh = torch.cat([x_tc, y_tc, t_tc], dim=1).to(\"cpu\")\n",
    "\n",
    "for i in range(len(time_fdm)):\n",
    "\n",
    "    pinn_start = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Cl_pinn, Cp_pinn = model_cpu(mesh).split(1, dim=1)\n",
    "\n",
    "    pinn_end = time.time()\n",
    "\n",
    "    pinn_time = pinn_end - pinn_start\n",
    "\n",
    "    speed_up.append(time_fdm[i] / pinn_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_speed_up = np.mean(speed_up)\n",
    "std_speed_up = np.std(speed_up)\n",
    "\n",
    "rmse = np.mean(\n",
    "    [\n",
    "        ((Cl_p[0] - Cl_f) ** 2 + (Cp_p[0] - Cp_f) ** 2) ** 0.5\n",
    "        for Cl_p, Cp_p, Cl_f, Cp_f in zip(\n",
    "            Cl_pinn, Cp_pinn, Cn_fdm.flatten(), Cb_fdm.flatten()\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "max_ae = np.max(\n",
    "    [\n",
    "        [((Cl_p[0] - Cl_f) ** 2) ** 0.5, ((Cp_p[0] - Cp_f) ** 2) ** 0.5]\n",
    "        for Cl_p, Cp_p, Cl_f, Cp_f in zip(\n",
    "            Cl_pinn, Cp_pinn, Cn_fdm.flatten(), Cb_fdm.flatten()\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    \"rmse\": rmse,\n",
    "    \"max_ae\": max_ae,\n",
    "    \"mean_speed_up\": mean_speed_up,\n",
    "    \"std_speed_up\": std_speed_up,\n",
    "    \"Cl_pinn\": Cl_pinn,\n",
    "    \"Cp_pinn\": Cp_pinn,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erro absoluto médio\", rmse)\n",
    "print(\"Erro absoluto máximo\", max_ae)\n",
    "print(\"Speed Up: {} +/-{}\".format(mean_speed_up, std_speed_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cl_pinn_np = Cl_pinn.detach().numpy().reshape(size_t , size_x , size_y )\n",
    "Cp_pinn_np = Cp_pinn.detach().numpy().reshape(size_t , size_x , size_y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(x_dom[0], x_dom[1], num=size_x, endpoint=True)\n",
    "y = np.linspace(y_dom[0], y_dom[1], num=size_y, endpoint=True)\n",
    "t = np.linspace(t_dom[0], t_dom[1], num=size_t, endpoint=True)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "time_plot = np.linspace(0, 10, num=5, endpoint=True, dtype=int)\n",
    "\n",
    "fig = plt.figure(figsize=[6 * len(time_plot), 14])\n",
    "\n",
    "fig.suptitle(\"Resposta imunológica a patógenos\", fontsize=16)\n",
    "\n",
    "\n",
    "for i, time in enumerate(time_plot):\n",
    "    # Plotango 3D\n",
    "    ax = fig.add_subplot(2, len(time_plot), i + 1)\n",
    "\n",
    "    vmin = np.min(Cp_pinn_np)\n",
    "    vmax = np.max(Cp_pinn_np)\n",
    "\n",
    "    contour = ax.contourf(\n",
    "        X,\n",
    "        Y,\n",
    "        Cp_pinn_np[time],\n",
    "        cmap=\"jet\",\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Con. de bactérias em t={}\".format(t[time]))\n",
    "    ax.set_xlabel(\"tempo\")\n",
    "    ax.set_ylabel(\"cond. inicial\")\n",
    "    colobar = fig.colorbar(contour, ticks=np.linspace(vmin, vmax, num=5))\n",
    "\n",
    "for i, time in enumerate(time_plot):\n",
    "    # Plotango 3D\n",
    "    ax = fig.add_subplot(2, len(time_plot), i + len(time_plot) + 1)\n",
    "\n",
    "    vmin = np.min(Cl_pinn_np)\n",
    "    vmax = np.max(Cl_pinn_np)\n",
    "\n",
    "    contour = ax.contourf(\n",
    "        X,\n",
    "        Y,\n",
    "        Cl_pinn_np[time],\n",
    "        cmap=\"jet\",\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Con. de bactérias em t={}\".format(t[time]))\n",
    "    ax.set_xlabel(\"tempo\")\n",
    "    ax.set_ylabel(\"cond. inicial\")\n",
    "    colobar = fig.colorbar(contour, ticks=np.linspace(vmin, vmax, num=5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cl_pinn_np = Cl_pinn.detach().numpy().reshape(size_t + 1, size_t + 1)\n",
    "Cp_pinn_np = Cp_pinn.detach().numpy().reshape(size_t + 1, size_t + 1)\n",
    "\n",
    "fig = plt.figure(figsize=[18, 14])\n",
    "\n",
    "fig.suptitle(\"Resposta imunológica a patógenos\", fontsize=16)\n",
    "\n",
    "\n",
    "# Plotango 3D\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "\n",
    "vmin = np.min(Cp_pinn_np)\n",
    "vmax = np.max(Cp_pinn_np)\n",
    "\n",
    "contour = ax.contourf(\n",
    "    tt,\n",
    "    ii,\n",
    "    Cp_pinn_np,\n",
    "    cmap=\"jet\",\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    ")\n",
    "ax.set_title(\"Con. de bactérias\")\n",
    "ax.set_xlabel(\"tempo\")\n",
    "ax.set_ylabel(\"cond. inicial\")\n",
    "colobar = fig.colorbar(contour, ticks=np.linspace(vmin, vmax, num=5))\n",
    "\n",
    "# Plotando 2D\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "\n",
    "vmin = np.min(Cl_pinn_np)\n",
    "vmax = np.max(Cl_pinn_np)\n",
    "\n",
    "contour = ax.contourf(\n",
    "    tt,\n",
    "    ii,\n",
    "    Cl_pinn_np,\n",
    "    cmap=\"jet\",\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    ")\n",
    "ax.set_title(\"Con. de neutrófilos\")\n",
    "ax.set_xlabel(\"tempo\")\n",
    "ax.set_ylabel(\"cond. inicial\")\n",
    "\n",
    "colobar = fig.colorbar(contour, ticks=np.linspace(vmin, vmax, num=5))\n",
    "\n",
    "# Plotango 3D\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "\n",
    "vmin = np.min(Cp_old)\n",
    "vmax = np.max(Cp_old)\n",
    "\n",
    "contour = ax.contourf(\n",
    "    tt,\n",
    "    ii,\n",
    "    Cp_old.reshape(size_t + 1, size_t + 1),\n",
    "    cmap=\"jet\",\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    ")\n",
    "ax.set_title(\"Con. real de bactérias\")\n",
    "ax.set_xlabel(\"tempo\")\n",
    "ax.set_ylabel(\"cond. inicial\")\n",
    "colobar = fig.colorbar(contour, ticks=np.linspace(vmin, vmax, num=5))\n",
    "\n",
    "# Plotando 2D\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4)\n",
    "\n",
    "vmin = np.min(Cl_old)\n",
    "vmax = np.max(Cl_old)\n",
    "\n",
    "contour = ax.contourf(\n",
    "    tt,\n",
    "    ii,\n",
    "    Cl_old.reshape(size_t + 1, size_t + 1),\n",
    "    cmap=\"jet\",\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    ")\n",
    "ax.set_title(\"Con. real de neutrófilos\")\n",
    "ax.set_xlabel(\"tempo\")\n",
    "ax.set_ylabel(\"cond. inicial\")\n",
    "\n",
    "colobar = fig.colorbar(contour, ticks=np.linspace(vmin, vmax, num=5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=[16, 27])\n",
    "\n",
    "fig.suptitle(\"Concentração de patógenos e leucócitos\", fontsize=16)\n",
    "\n",
    "\n",
    "vmin = 0\n",
    "\n",
    "cp_real_1 = Cp_old[0, :]\n",
    "cl_real_1 = Cl_old[0, :]\n",
    "cp_pinn_1 = Cp_pinn_np[0, :]\n",
    "cl_pinn_1 = Cl_pinn_np[0, :]\n",
    "ini_1 = initial[0 * (size_t + 1)].cpu().detach().numpy()[0]\n",
    "\n",
    "cp_real_2 = Cp_old[50, :]\n",
    "cl_real_2 = Cl_old[50, :]\n",
    "cp_pinn_2 = Cp_pinn_np[50, :]\n",
    "cl_pinn_2 = Cl_pinn_np[50, :]\n",
    "ini_2 = initial[50 * (size_t + 1)].cpu().detach().numpy()[0]\n",
    "\n",
    "cp_real_3 = Cp_old[100, :]\n",
    "cl_real_3 = Cl_old[100, :]\n",
    "cp_pinn_3 = Cp_pinn_np[100, :]\n",
    "cl_pinn_3 = Cl_pinn_np[100, :]\n",
    "ini_3 = initial[100 * (size_t + 1)].cpu().detach().numpy()[0]\n",
    "\n",
    "# Plotango 3D\n",
    "ax = fig.add_subplot(3, 1, 1)\n",
    "\n",
    "ax.plot(t_np, cp_real_1, label=\"Pat fdm = {:.2f}\".format(ini_1))\n",
    "ax.plot(t_np, cl_real_1, label=\"Leu. fdm = {:.2f}\".format(ini_1))\n",
    "ax.plot(t_np, cp_pinn_1, \"--\", label=\"Pat. pinn fag. = {:.2f}\".format(ini_1))\n",
    "ax.plot(t_np, cl_pinn_1, \"-.\", label=\"Leu. pinn fag. = {:.2f}\".format(ini_1))\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "\n",
    "vmax = np.max(\n",
    "    [\n",
    "        np.max(cp_real_1),\n",
    "        np.max(cl_real_1),\n",
    "        np.max(cp_pinn_1),\n",
    "        np.max(cl_pinn_1),\n",
    "    ]\n",
    ")\n",
    "ax.set_ylim(vmin, vmax + 0.1)\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "ax = fig.add_subplot(3, 1, 2)\n",
    "\n",
    "ax.plot(t_np, cp_real_2, label=\"Pat fdm = {:.2f}\".format(ini_2))\n",
    "ax.plot(t_np, cl_real_2, label=\"Leu. fdm = {:.2f}\".format(ini_2))\n",
    "ax.plot(t_np, cp_pinn_2, \"--\", label=\"Pat. pinn fag. = {:.2f}\".format(ini_2))\n",
    "ax.plot(t_np, cl_pinn_2, \"-.\", label=\"Leu. pinn fag. = {:.2f}\".format(ini_2))\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "vmax = np.max(\n",
    "    [\n",
    "        np.max(cp_real_2),\n",
    "        np.max(cl_real_2),\n",
    "        np.max(cp_pinn_2),\n",
    "        np.max(cl_pinn_2),\n",
    "    ]\n",
    ")\n",
    "ax.set_ylim(vmin, vmax + 0.1)\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "ax = fig.add_subplot(3, 1, 3)\n",
    "\n",
    "ax.plot(t_np, cp_real_3, label=\"Pat fdm = {:.2f}\".format(ini_3))\n",
    "ax.plot(t_np, cl_real_3, label=\"Leu. fdm = {:.2f}\".format(ini_3))\n",
    "ax.plot(t_np, cp_pinn_3, \"--\", label=\"Pat. pinn fag. = {:.2f}\".format(ini_3))\n",
    "ax.plot(t_np, cl_pinn_3, \"-.\", label=\"Leu. pinn fag. = {:.2f}\".format(ini_3))\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "vmax = np.max(\n",
    "    [\n",
    "        np.max(cp_real_3),\n",
    "        np.max(cl_real_3),\n",
    "        np.max(cp_pinn_3),\n",
    "        np.max(cl_pinn_3),\n",
    "    ]\n",
    ")\n",
    "ax.set_ylim(vmin, vmax + 0.1)\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

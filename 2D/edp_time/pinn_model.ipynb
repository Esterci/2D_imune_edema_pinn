{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definições iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "with open(\"control_dicts/constant_properties.json\", \"r\") as openfile:\n",
    "    # Reading from json file\n",
    "    constant_properties = json.load(openfile)\n",
    "\n",
    "Db = constant_properties[\"Db\"]\n",
    "Dn = constant_properties[\"Dn\"]\n",
    "phi = constant_properties[\"phi\"]\n",
    "cb = constant_properties[\"cb\"]\n",
    "lambd_nb = constant_properties[\"lambd_nb\"]\n",
    "mi_n = constant_properties[\"mi_n\"]\n",
    "lambd_bn = constant_properties[\"lambd_bn\"]\n",
    "y_n = constant_properties[\"y_n\"]\n",
    "Cn_max = constant_properties[\"Cn_max\"]\n",
    "X_nb = constant_properties[\"X_nb\"]\n",
    "central_ini_cond = constant_properties[\"central_ini_cond\"]\n",
    "ini_cond_var = constant_properties[\"ini_cond_var\"]\n",
    "\n",
    "# Opening JSON file\n",
    "with open(\"control_dicts/mesh_properties.json\", \"r\") as openfile:\n",
    "    # Reading from json file\n",
    "    mesh_properties = json.load(openfile)\n",
    "\n",
    "h = mesh_properties[\"h\"]\n",
    "k = mesh_properties[\"k\"]\n",
    "x_dom = mesh_properties[\"x_dom\"]\n",
    "y_dom = mesh_properties[\"y_dom\"]\n",
    "t_dom = mesh_properties[\"t_dom\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_infection_site(struct_name):\n",
    "\n",
    "    center_str = (struct_name).split(\"__\")[-2].split(\"(\")[-1].split(\")\")[0].split(\",\")\n",
    "\n",
    "    center = (float(center_str[0]), float(center_str[1]))\n",
    "\n",
    "    radius = float(struct_name.split(\"__\")[-1].split(\"--\")[-1].split(\".pkl\")[0])\n",
    "\n",
    "    return center, radius\n",
    "\n",
    "\n",
    "def read_files(path):\n",
    "    file_list = sorted(glob(path + \"/*\"))\n",
    "\n",
    "    speed_up_list = []\n",
    "    Cb_list = []\n",
    "    Cn_list = []\n",
    "\n",
    "    for file in file_list:\n",
    "\n",
    "        variable = lambda a: a.split(\"/\")[-1].split(\"__\")[0]\n",
    "\n",
    "        if variable(file) == \"Cl\":\n",
    "            Cn_list.append(file)\n",
    "\n",
    "        elif variable(file) == \"Cp\":\n",
    "            Cb_list.append(file)\n",
    "\n",
    "        elif variable(file) == \"speed_up\":\n",
    "            speed_up_list.append(file)\n",
    "\n",
    "    return Cn_list, Cb_list, speed_up_list\n",
    "\n",
    "\n",
    "def change_dim_order(np_array):\n",
    "    # (2, 2, 100001, 21, 21)\n",
    "    sim_shape = np_array.shape\n",
    "\n",
    "    form_array = np.zeros(\n",
    "        (\n",
    "            sim_shape[2],\n",
    "            sim_shape[0],\n",
    "            sim_shape[1],\n",
    "            sim_shape[3],\n",
    "            sim_shape[4],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for i in range(sim_shape[2]):\n",
    "        form_array[i, :, :, :, :] = np_array[:, :, i, :, :]\n",
    "\n",
    "    return form_array\n",
    "\n",
    "\n",
    "def format_array(Cb_list, Cn_list):\n",
    "\n",
    "    for i, (Cb_file, Cn_file) in enumerate(zip(Cb_list, Cn_list)):\n",
    "        with open(Cb_file, \"rb\") as f:\n",
    "            new_Cb = pk.load(f)\n",
    "\n",
    "        with open(Cn_file, \"rb\") as f:\n",
    "            new_Cn = pk.load(f)\n",
    "\n",
    "        sim_shape = new_Cb.shape\n",
    "\n",
    "        if i == 0:\n",
    "            Cb = np.zeros(\n",
    "                (len(Cb_list), sim_shape[0], sim_shape[1], sim_shape[2], sim_shape[3])\n",
    "            )\n",
    "\n",
    "            Cn = np.zeros(\n",
    "                (len(Cn_list), sim_shape[0], sim_shape[1], sim_shape[2], sim_shape[3])\n",
    "            )\n",
    "\n",
    "            center_x = np.zeros(len(Cb_list))\n",
    "\n",
    "            center_y = np.zeros(len(Cb_list))\n",
    "\n",
    "            radius_array = np.zeros(len(Cb_list))\n",
    "\n",
    "        Cb[i, :, :, :, :] = new_Cb\n",
    "\n",
    "        Cn[i, :, :, :, :] = new_Cn\n",
    "\n",
    "        center, radius = get_infection_site(Cb_file)\n",
    "\n",
    "        center_x[i], center_y[i] = center\n",
    "\n",
    "        radius_array[i] = radius\n",
    "\n",
    "    return Cb, Cn, center_x, center_y, radius_array\n",
    "\n",
    "\n",
    "Cn_list, Cb_list, speed_up_list = read_files(\"fvm_sim\")\n",
    "\n",
    "Cb_fvm, Cn_fvm, center_x_array, center_y_array, radius_array = format_array(\n",
    "    Cb_list[:1], Cn_list[:1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps in time = 10001\n",
      "Steps in space_x = 20\n",
      "Steps in space_y = 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_mesh_properties(\n",
    "    x_dom,\n",
    "    y_dom,\n",
    "    t_dom,\n",
    "    h,\n",
    "    k,\n",
    "    central_ini_cond,\n",
    "    ini_cond_var,\n",
    "    n_ini,\n",
    "    verbose=True,\n",
    "):\n",
    "\n",
    "    size_x = int(((x_dom[1] - x_dom[0]) / (h)))\n",
    "    size_y = int(((y_dom[1] - y_dom[0]) / (h)))\n",
    "    size_t = int(((t_dom[1] - t_dom[0]) / (k)) + 1)\n",
    "\n",
    "    initial_cond = np.linspace(\n",
    "        central_ini_cond * (1 - ini_cond_var),\n",
    "        central_ini_cond * (1 + ini_cond_var),\n",
    "        num=n_ini,\n",
    "        endpoint=True,\n",
    "        dtype=np.float16,\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Steps in time = {:d}\\nSteps in space_x = {:d}\\nSteps in space_y = {:d}\\n\".format(\n",
    "                size_t,\n",
    "                size_x,\n",
    "                size_y,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return (size_x, size_y, size_t, initial_cond)\n",
    "\n",
    "\n",
    "size_x, size_y, size_t, initial_cond = get_mesh_properties(\n",
    "    x_dom, y_dom, t_dom, h, k, central_ini_cond, ini_cond_var, Cb_fvm.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_mesh(\n",
    "    t_dom,\n",
    "    x_dom,\n",
    "    y_dom,\n",
    "    size_t,\n",
    "    size_x,\n",
    "    size_y,\n",
    "    center_x_array,\n",
    "    center_y_array,\n",
    "    initial_cond,\n",
    "    radius_array,\n",
    "):\n",
    "    t_np = np.linspace(t_dom[0], t_dom[1], num=size_t, endpoint=False, dtype=np.float32)\n",
    "    x_np = np.linspace(x_dom[0], x_dom[1], num=size_x, endpoint=False, dtype=np.float32)\n",
    "    y_np = np.linspace(y_dom[0], y_dom[1], num=size_y, endpoint=False, dtype=np.float32)\n",
    "    infection_idx = np.linspace(\n",
    "        0, len(center_x_array), num=len(center_x_array), endpoint=False, dtype=np.int32\n",
    "    )\n",
    "\n",
    "    # Change first with second dimension for np.meshgrid match with\n",
    "    # torch.mashgrid and C flattening logic\n",
    "\n",
    "    initial_mesh, infection_mesh, t_mesh, x_mesh, y_mesh = np.meshgrid(\n",
    "        initial_cond, infection_idx, t_np, x_np, y_np\n",
    "    )\n",
    "\n",
    "    center_x_mesh = np.zeros(infection_mesh.ravel().shape)\n",
    "    center_y_mesh = np.zeros(infection_mesh.ravel().shape)\n",
    "    radius_mesh = np.zeros(infection_mesh.ravel().shape)\n",
    "\n",
    "    for i, idx in enumerate(infection_mesh.ravel()):\n",
    "\n",
    "        center_x_mesh[i] = center_x_array[idx]\n",
    "        center_y_mesh[i] = center_y_array[idx]\n",
    "        radius_mesh[i] = radius_array[idx]\n",
    "\n",
    "    return (\n",
    "        initial_mesh,\n",
    "        center_x_mesh,\n",
    "        center_y_mesh,\n",
    "        radius_mesh,\n",
    "        t_mesh,\n",
    "        x_mesh,\n",
    "        y_mesh,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_mesh(\n",
    "    t_dom,\n",
    "    x_dom,\n",
    "    y_dom,\n",
    "    size_t,\n",
    "    size_x,\n",
    "    size_y,\n",
    "    center_x_array,\n",
    "    center_y_array,\n",
    "    initial_cond,\n",
    "    radius_array,\n",
    "    Cb_fvm,\n",
    "    Cn_fvm,\n",
    "):\n",
    "\n",
    "    (\n",
    "        initial_mesh,\n",
    "        center_x_mesh,\n",
    "        center_y_mesh,\n",
    "        radius_mesh,\n",
    "        t_mesh,\n",
    "        x_mesh,\n",
    "        y_mesh,\n",
    "    ) = create_input_mesh(\n",
    "        t_dom,\n",
    "        x_dom,\n",
    "        y_dom,\n",
    "        size_t,\n",
    "        size_x,\n",
    "        size_y,\n",
    "        center_x_array,\n",
    "        center_y_array,\n",
    "        initial_cond,\n",
    "        radius_array,\n",
    "    )\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "\n",
    "    print(\"device:\", device)\n",
    "\n",
    "    initial_tc = (\n",
    "        torch.tensor(initial_mesh, dtype=torch.float32).reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "    center_x_tc = (\n",
    "        torch.tensor(center_x_mesh, dtype=torch.float32).reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "    center_y_tc = (\n",
    "        torch.tensor(center_y_mesh, dtype=torch.float32).reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "    radius_tc = torch.tensor(radius_mesh, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "    t_tc = torch.tensor(t_mesh, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "    x_tc = torch.tensor(x_mesh, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "    y_tc = torch.tensor(y_mesh, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "    target = torch.tensor(\n",
    "        np.hstack((Cn_fvm.reshape(-1, 1), Cb_fvm.reshape(-1, 1))), dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        initial_tc,\n",
    "        center_x_tc,\n",
    "        center_y_tc,\n",
    "        radius_tc,\n",
    "        t_tc,\n",
    "        x_tc,\n",
    "        y_tc,\n",
    "        target,\n",
    "        device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "(initial_tc, center_x_tc, center_y_tc, radius_tc, t_tc, x_tc, y_tc, target, device) = (\n",
    "    make_training_mesh(\n",
    "        t_dom,\n",
    "        x_dom,\n",
    "        y_dom,\n",
    "        size_t,\n",
    "        size_x,\n",
    "        size_y,\n",
    "        center_x_array,\n",
    "        center_y_array,\n",
    "        initial_cond,\n",
    "        radius_array,\n",
    "        Cb_fvm,\n",
    "        Cn_fvm,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archtecture handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_dict = {\n",
    "    \"Elu\": nn.ELU,\n",
    "    \"LeakyReLU\": nn.LeakyReLU,\n",
    "    \"Sigmoid\": nn.Sigmoid,\n",
    "    \"Softplus\": nn.Softplus,\n",
    "    \"Tanh\": nn.Tanh,\n",
    "    \"Linear\": nn.Linear,\n",
    "    \"ReLU\": nn.ReLU,\n",
    "    \"RReLU\": nn.RReLU,\n",
    "    \"SELU\": nn.SELU,\n",
    "    \"CELU\": nn.CELU,\n",
    "    \"GELU\": nn.GELU,\n",
    "    \"SiLU\": nn.SiLU,\n",
    "    \"GLU\": nn.GLU,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_str = \"Tanh--32__Tanh--32__Tanh--32__GELU--32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(arch_str):\n",
    "    hidden_layers = arch_str.split(\"__\")\n",
    "\n",
    "    modules = []\n",
    "\n",
    "    for params in hidden_layers:\n",
    "        if len(params) != 0:\n",
    "            activation, out_neurons = params.split(\"--\")\n",
    "\n",
    "            if len(modules) == 0:\n",
    "                if activation == \"Linear\":\n",
    "                    modules.append(activation_dict[activation](7, int(out_neurons)))\n",
    "\n",
    "                else:\n",
    "                    modules.append(nn.Linear(7, int(out_neurons)))\n",
    "                    modules.append(activation_dict[activation]())\n",
    "\n",
    "            else:\n",
    "                if activation == \"Linear\":\n",
    "                    modules.append(\n",
    "                        activation_dict[activation](int(in_neurons), int(out_neurons))\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    modules.append(nn.Linear(int(in_neurons), int(out_neurons)))\n",
    "                    modules.append(activation_dict[activation]())\n",
    "\n",
    "            in_neurons = out_neurons\n",
    "\n",
    "    modules.append(nn.Linear(int(in_neurons), 2))\n",
    "\n",
    "    return nn.Sequential(*modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=7, out_features=32, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (5): Tanh()\n",
      "  (6): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (7): GELU(approximate='none')\n",
      "  (8): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = generate_model(arch_str).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_torch(dataset):\n",
    "    with torch.no_grad():\n",
    "        dt_min = torch.min(dataset, 0).values\n",
    "        dt_max = torch.max(dataset, 0).values\n",
    "        normalized = (dataset - dt_min) / (dt_max - dt_min)\n",
    "\n",
    "    return normalized.requires_grad_(True), dt_min, dt_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data_input(data_input, steps):\n",
    "    with torch.no_grad():\n",
    "        dataset = data_input.reshape(steps, steps, 2)\n",
    "        normalized = torch.zeros_like(dataset)\n",
    "        for i in range(len(dataset)):\n",
    "            dt_min = torch.min(dataset[i], 0).values\n",
    "            dt_max = torch.max(dataset[i], 0).values\n",
    "            normalized[i] = (dataset[i] - dt_min) / (dt_max - dt_min)\n",
    "\n",
    "    return normalized.reshape((steps) * (steps), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(dataset, dt_min, dt_max):\n",
    "    return (dt_max - dt_min) * dataset + dt_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(x, y):\n",
    "    Data_num = np.arange(x.shape[0])\n",
    "    np.random.shuffle(Data_num)\n",
    "\n",
    "    return x[Data_num], y[Data_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x, y, device, test_size=0.5, shuffle=True):\n",
    "    with torch.no_grad():\n",
    "        if shuffle:\n",
    "            x, y = shuffle_data(x, y)\n",
    "        if test_size < 1:\n",
    "            train_ratio = len(x) - int(len(x) * test_size)\n",
    "            x_train, x_test = x[:train_ratio], x[train_ratio:]\n",
    "            y_train, y_test = y[:train_ratio], y[train_ratio:]\n",
    "            return (\n",
    "                x_train.requires_grad_(True).to(device),\n",
    "                x_test.requires_grad_(True).to(device),\n",
    "                y_train.requires_grad_(True).to(device),\n",
    "                y_test.requires_grad_(True).to(device),\n",
    "            )\n",
    "        elif test_size in range(1, len(x)):\n",
    "            x_train, x_test = x[test_size:], x[:test_size]\n",
    "            y_train, y_test = y[test_size:], y[:test_size]\n",
    "            return (\n",
    "                x_train.requires_grad_(True).to(device),\n",
    "                x_test.requires_grad_(True).to(device),\n",
    "                y_train.requires_grad_(True).to(device),\n",
    "                y_test.requires_grad_(True).to(device),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_points(num_points):\n",
    "    initial = torch.rand(num_points, 1) * (0.6 - 0.4) + 0.4\n",
    "    center_x = torch.rand(num_points, 1)\n",
    "    center_y = torch.rand(num_points, 1)\n",
    "    radius = torch.rand(num_points, 1) * (0.2 - 0.1) + 0.1\n",
    "    t = torch.rand(num_points, 1) * 10\n",
    "    x = torch.rand(num_points, 1)\n",
    "    y = torch.rand(num_points, 1)\n",
    "\n",
    "    return (\n",
    "        initial.requires_grad_(False),\n",
    "        center_x.requires_grad_(False),\n",
    "        center_y.requires_grad_(False),\n",
    "        radius.requires_grad_(False),\n",
    "        t.requires_grad_(False),\n",
    "        x.requires_grad_(False),\n",
    "        y.requires_grad_(False),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_boundary_points(num_points):\n",
    "    \n",
    "    y_boundary = torch.rand(num_points)\n",
    "\n",
    "    if torch.rand(1) > 0.5:\n",
    "        x_boundary, y_boundary = y_boundary, x_boundary\n",
    "        n = torch.tensor([[0.0, -1.0], [0.0, 1.0]]).repeat(num_points // 2, 1)\n",
    "    else:\n",
    "        n = torch.tensor([[-1.0, 0.0], [1.0, 0.0]]).repeat(num_points // 2, 1)\n",
    "\n",
    "    return (\n",
    "        x_boundary.view(-1, 1),\n",
    "        y_boundary.view(-1, 1),\n",
    "        n,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_condition_points(data_input):\n",
    "\n",
    "    initial_tc = data_input[:,0]\n",
    "    center_x_tc= data_input[:,1]\n",
    "    center_y_tc= data_input[:,2]\n",
    "    radius_tc= data_input[:,3]\n",
    "    x_tc= data_input[:,5]\n",
    "    y_tc= data_input[:,6]\n",
    "\n",
    "    # Calculate squared distances from each point to the circle centers\n",
    "    squared_distances = (x_tc - center_x_tc) ** 2 + (y_tc - center_y_tc) ** 2\n",
    "\n",
    "    # Create a mask for points inside the circle\n",
    "    inside_circle_mask = squared_distances <= radius_tc**2\n",
    "\n",
    "    # Initialize the tensor and set the values for points inside the circle\n",
    "    C_init = torch.zeros((len(x_tc), 2))\n",
    "    C_init[:, 1] = inside_circle_mask.ravel() * initial_tc.ravel()\n",
    "\n",
    "    return C_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_condition(\n",
    "    model, device, initial, center_x, center_y, radius, t_b, x_b, y_b, n, Dn, X_nb, Db\n",
    "):\n",
    "\n",
    "    input_boundary = (\n",
    "        torch.cat(\n",
    "            [\n",
    "                initial,\n",
    "                center_x,\n",
    "                center_y,\n",
    "                radius,\n",
    "                t_b,\n",
    "                x_b,\n",
    "                y_b,\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        .to(device)\n",
    "        .requires_grad_(True)\n",
    "    )\n",
    "\n",
    "    print(\"input_boundary.shape\", input_boundary.shape)\n",
    "\n",
    "    Cp, Cl = model(input_boundary).tensor_split(2, dim=1)\n",
    "\n",
    "    del input_boundary\n",
    "    nx, ny = n.tensor_split(2, dim=1)\n",
    "\n",
    "    if nx[0].item() != 0:\n",
    "        dCp_dx = torch.autograd.grad(\n",
    "            Cp,\n",
    "            x_b,\n",
    "            grad_outputs=torch.ones_like(Cp),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )\n",
    "\n",
    "        dCl_dx = torch.autograd.grad(\n",
    "            Cl,\n",
    "            x_b,\n",
    "            grad_outputs=torch.ones_like(Cl),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )\n",
    "\n",
    "        Cl_boundary = torch.mul(\n",
    "            ((Dn * dCl_dx[0]) - X_nb * torch.mul(Cl, dCp_dx[0])), nx\n",
    "        )\n",
    "\n",
    "        Cp_boundary = torch.mul((Db * dCp_dx[0]), nx)\n",
    "\n",
    "        return torch.cat([Cl_boundary, Cp_boundary], dim=1)\n",
    "\n",
    "    else:\n",
    "        dCp_dy = torch.autograd.grad(\n",
    "            Cp,\n",
    "            y_b,\n",
    "            grad_outputs=torch.ones_like(Cp),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )\n",
    "\n",
    "        dCl_dy = torch.autograd.grad(\n",
    "            Cl,\n",
    "            y_b,\n",
    "            grad_outputs=torch.ones_like(Cl),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )\n",
    "\n",
    "        Cl_boundary = torch.mul(\n",
    "            ((Dn * dCl_dy[0]) - X_nb * torch.mul(Cl, dCp_dy[0])), ny\n",
    "        )\n",
    "\n",
    "        Cp_boundary = torch.mul((Db * dCp_dy[0]), ny)\n",
    "\n",
    "        return torch.cat([Cl_boundary, Cp_boundary], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde(\n",
    "    model,\n",
    "    device,\n",
    "    initial,\n",
    "    center_x,\n",
    "    center_y,\n",
    "    radius,\n",
    "    t,\n",
    "    x,\n",
    "    y,\n",
    "    cb,\n",
    "    lambd_nb,\n",
    "    Db,\n",
    "    y_n,\n",
    "    Cn_max,\n",
    "    lambd_bn,\n",
    "    mi_n,\n",
    "    Dn,\n",
    "    X_nb,\n",
    "):\n",
    "\n",
    "    input_pde = (\n",
    "        torch.cat(\n",
    "            [\n",
    "                initial,\n",
    "                center_x,\n",
    "                center_y,\n",
    "                radius,\n",
    "                t,\n",
    "                x,\n",
    "                y,\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        .requires_grad_(True)\n",
    "    )\n",
    "\n",
    "    print(\"input_pde.shape\",input_pde.shape)\n",
    "\n",
    "\n",
    "\n",
    "    Cl, Cp = model(input_pde).tensor_split(2, dim=1).to(device)\n",
    "\n",
    "    del input_pde\n",
    "    \n",
    "    # Calculating Cp value\n",
    "\n",
    "    dCp_dx, dCp_dy = torch.autograd.grad(\n",
    "        Cp,\n",
    "        [x, y],\n",
    "        grad_outputs=torch.ones_like(Cp),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )\n",
    "\n",
    "    dCp_dx_2 = torch.autograd.grad(\n",
    "        dCp_dx,\n",
    "        x,\n",
    "        grad_outputs=torch.ones_like(dCp_dx),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    dCp_dy_2 = torch.autograd.grad(\n",
    "        dCp_dy,\n",
    "        y,\n",
    "        grad_outputs=torch.ones_like(dCp_dy),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    dCp_dt = torch.autograd.grad(\n",
    "        Cp,\n",
    "        t,\n",
    "        grad_outputs=torch.ones_like(Cp),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    qb = cb * Cp\n",
    "    rb = lambd_nb * torch.mul(Cl, Cp)\n",
    "\n",
    "    Cp_eq = Db * (dCp_dx_2 + dCp_dy_2) - rb + qb - dCp_dt\n",
    "\n",
    "    # Calculating Cl value\n",
    "\n",
    "    dCl_dx, dCl_dy = torch.autograd.grad(\n",
    "        Cl,\n",
    "        [x, y],\n",
    "        grad_outputs=torch.ones_like(Cl),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )\n",
    "\n",
    "    dCl_dx_2 = torch.autograd.grad(\n",
    "        dCl_dx,\n",
    "        x,\n",
    "        grad_outputs=torch.ones_like(dCl_dx),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    dCl_dy_2 = torch.autograd.grad(\n",
    "        dCl_dy,\n",
    "        y,\n",
    "        grad_outputs=torch.ones_like(dCl_dy),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    dCl_dt = torch.autograd.grad(\n",
    "        Cl,\n",
    "        t,\n",
    "        grad_outputs=torch.ones_like(Cl),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    qn = y_n * torch.mul(Cp, (Cn_max - Cl))\n",
    "    rn = lambd_bn * torch.mul(Cl, Cp) + mi_n * Cl\n",
    "\n",
    "    Cl_eq = (\n",
    "        Dn * (dCl_dx_2 + dCl_dy_2)\n",
    "        - X_nb\n",
    "        * (\n",
    "            (torch.mul(dCl_dx, dCp_dx) + torch.mul(Cl, dCp_dx_2))\n",
    "            + (torch.mul(dCl_dy, dCp_dy) + torch.mul(Cl, dCp_dy_2))\n",
    "        )\n",
    "        - rn\n",
    "        + qn\n",
    "    ) - dCl_dt\n",
    "\n",
    "    return torch.cat([Cl_eq, Cp_eq], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_epochs,\n",
    "        batch_size,\n",
    "        decay_rate,\n",
    "        model,\n",
    "        initial_tc,\n",
    "        center_x_tc,\n",
    "        center_y_tc,\n",
    "        radius_tc,\n",
    "        t_tc,\n",
    "        x_tc,\n",
    "        y_tc,\n",
    "        target,\n",
    "        device,\n",
    "        n_points,\n",
    "        constant_properties,\n",
    "        norm_weights=None,\n",
    "        validation=None,\n",
    "        tolerance=None,\n",
    "        patience=10,\n",
    "    ):\n",
    "\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.decay_rate = decay_rate\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.n_points = n_points\n",
    "        self.constant_properties = constant_properties\n",
    "        self.norm_weights = norm_weights\n",
    "        self.validation = validation\n",
    "        self.tolerance = tolerance\n",
    "        self.patience = patience\n",
    "\n",
    "        data_input = torch.cat(\n",
    "            [\n",
    "                initial_tc,\n",
    "                center_x_tc,\n",
    "                center_y_tc,\n",
    "                radius_tc,\n",
    "                t_tc,\n",
    "                x_tc,\n",
    "                y_tc,\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        if self.validation:\n",
    "            (\n",
    "                self.train_data,\n",
    "                self.test_data,\n",
    "                self.train_target,\n",
    "                self.test_target,\n",
    "            ) = train_test_split(\n",
    "                data_input,\n",
    "                target,\n",
    "                device,\n",
    "                test_size=self.validation,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            self.train_data = data_input.to(device)\n",
    "            self.test_data = None\n",
    "            self.train_target = target.to(device)\n",
    "            self.test_target = None\n",
    "\n",
    "        del data_input\n",
    "\n",
    "        self.batch = torch.zeros(batch_size, self.train_data.shape(0)).to(device)\n",
    "        self.random_batch = torch.zeros(batch_size, self.train_data.shape(0)).to(device)\n",
    "\n",
    "        pass\n",
    "\n",
    "    def loss_func(\n",
    "        self,\n",
    "    ):\n",
    "        self.batch = self.test_data[self.i : self.i + self.batch_size, :]\n",
    "\n",
    "        C_initial_batch = initial_condition_points(self.batch).to(self.device)\n",
    "\n",
    "        # Computing intial loss\n",
    "        t_initial = torch.zeros((len(self.batch), 1)).to(self.device)\n",
    "\n",
    "        mesh_ini = torch.cat(\n",
    "            [self.batch[:, :5], t_initial, self.batch[:, 6:]],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        print(\"self.batch.shape\", self.batch.shape)\n",
    "        print(\"t_initial.shape\", t_initial.shape)\n",
    "        print(\"mesh_ini.shape\", mesh_ini.shape)\n",
    "        C_initial_pred = model(mesh_ini)\n",
    "\n",
    "        print(\"C_initial_pred.shape\", C_initial_pred.shape)\n",
    "        print(\n",
    "            \"C_initial_batch.shape\",\n",
    "            C_initial_batch.shape,\n",
    "        )\n",
    "\n",
    "        self.loss_initial = self.criterion(C_initial_batch, C_initial_pred)\n",
    "\n",
    "        del mesh_ini\n",
    "        del t_initial\n",
    "        del C_initial_batch\n",
    "\n",
    "        # Computing pde loss\n",
    "\n",
    "        initial, center_x, center_y, radius, t, x, y = generate_training_points(\n",
    "            self.n_points\n",
    "        )\n",
    "\n",
    "        predicted_pde = pde(\n",
    "            model,\n",
    "            self.device,\n",
    "            initial,\n",
    "            center_x,\n",
    "            center_y,\n",
    "            radius,\n",
    "            t,\n",
    "            x,\n",
    "            y,\n",
    "            self.constant_properties[\"cb\"],\n",
    "            self.constant_properties[\"lambd_nb\"],\n",
    "            self.constant_properties[\"Db\"],\n",
    "            self.constant_properties[\"y_n\"],\n",
    "            self.constant_properties[\"Cn_max\"],\n",
    "            self.constant_properties[\"lambd_bn\"],\n",
    "            self.constant_properties[\"mi_n\"],\n",
    "            self.constant_properties[\"Dn\"],\n",
    "            self.constant_properties[\"X_nb\"],\n",
    "        )\n",
    "\n",
    "        self.loss_pde = self.criterion(\n",
    "            predicted_pde,\n",
    "            torch.zeros_like(predicted_pde),\n",
    "        )\n",
    "\n",
    "        # Computing boundary loss\n",
    "\n",
    "        x_bnd, y_bnd, n_bnd = generate_boundary_points(self.n_points)\n",
    "\n",
    "        predicted_boundary = boundary_condition(\n",
    "            model,\n",
    "            self.device,\n",
    "            initial,\n",
    "            center_x,\n",
    "            center_y,\n",
    "            radius,\n",
    "            t,\n",
    "            x_bnd,\n",
    "            y_bnd,\n",
    "            n_bnd,\n",
    "            self.constant_properties[\"Dn\"],\n",
    "            self.constant_properties[\"X_nb\"],\n",
    "            self.constant_properties[\"Db\"],\n",
    "        )\n",
    "\n",
    "        self.loss_boundary = self.criterion(\n",
    "            predicted_boundary,\n",
    "            torch.zeros_like(predicted_boundary),\n",
    "        )\n",
    "\n",
    "        # Computing data loss\n",
    "\n",
    "        C_pred = model(self.batch.to(device))\n",
    "\n",
    "        self.loss_data = self.criterion(self.batch, C_pred)\n",
    "\n",
    "        self.loss = (\n",
    "            10 * self.loss_initial\n",
    "            + self.loss_pde\n",
    "            + self.loss_boundary\n",
    "            + self.loss_data * 10\n",
    "        )\n",
    "\n",
    "        self.loss.backward()\n",
    "\n",
    "        return self.loss\n",
    "\n",
    "    def execute(\n",
    "        self,\n",
    "    ):\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "        dt_min, dt_max = self.norm_weights if self.norm_weights else (0, 1)\n",
    "\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        self.lr_scheduler = optim.lr_scheduler.ExponentialLR(\n",
    "            optimizer=self.optimizer, gamma=self.decay_rate\n",
    "        )\n",
    "\n",
    "        C_pde_loss_it = torch.zeros(self.n_epochs)\n",
    "        C_data_loss_it = torch.zeros(self.n_epochs)\n",
    "        C_boundary_loss_it = torch.zeros(self.n_epochs)\n",
    "        C_initial_loss_it = torch.zeros(self.n_epochs)\n",
    "        val_loss_it = torch.zeros(self.n_epochs)\n",
    "\n",
    "        patience_count = 0\n",
    "        val_loss = torch.tensor([1000])\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            for self.i in range(0, len(self.train_data), self.batch_size):\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                self.optimizer.step(self.loss_func)\n",
    "                self.lr_scheduler.step()\n",
    "\n",
    "            # Computing validation loss\n",
    "\n",
    "            if self.validation:\n",
    "                with torch.no_grad():\n",
    "                    val_old = val_loss\n",
    "                    val_loss = self.criterion(\n",
    "                        self.test_data, model(self.test_data_input)\n",
    "                    )\n",
    "\n",
    "            C_pde_loss_it[epoch] = self.loss_pde.item()\n",
    "            C_boundary_loss_it[epoch] = self.loss_boundary.item()\n",
    "            C_initial_loss_it[epoch] = self.loss_initial.item()\n",
    "            C_data_loss_it[epoch] = self.loss_data.item()\n",
    "            val_loss_it[epoch] = val_loss.item() if self.validation else 0\n",
    "\n",
    "            if ((epoch + 1) % 100) == 0 or (epoch == 0):\n",
    "                print(\n",
    "                    f\"Finished epoch {epoch+1}, latest loss {self.loss}, validation loss {val_loss.item()}\"\n",
    "                    if self.validation\n",
    "                    else f\"Finished epoch {epoch+1}, latest loss {self.loss}\"\n",
    "                )\n",
    "\n",
    "            if self.tolerance:\n",
    "\n",
    "                if (\n",
    "                    abs(val_old.item() - val_loss.item()) / val_old.item()\n",
    "                    < self.tolerance\n",
    "                ):\n",
    "                    patience_count += 1\n",
    "\n",
    "                else:\n",
    "                    patience_count = 0\n",
    "\n",
    "                if patience_count >= self.patience:\n",
    "\n",
    "                    C_pde_loss_it = C_pde_loss_it[:epoch]\n",
    "                    C_boundary_loss_it = C_boundary_loss_it[:epoch]\n",
    "                    C_initial_loss_it = C_initial_loss_it[:epoch]\n",
    "                    C_data_loss_it = C_data_loss_it[:epoch]\n",
    "                    val_loss_it = val_loss_it[:epoch]\n",
    "\n",
    "                    print(\"Early break!\")\n",
    "\n",
    "                    break\n",
    "\n",
    "        return (\n",
    "            model,\n",
    "            C_pde_loss_it,\n",
    "            C_boundary_loss_it,\n",
    "            C_initial_loss_it,\n",
    "            C_data_loss_it,\n",
    "            val_loss_it,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0423367023468018\n"
     ]
    }
   ],
   "source": [
    "decay_rate = 0.9985\n",
    "n_epochs = 1\n",
    "batch_size = 40004000\n",
    "\n",
    "trainer = train(\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    decay_rate=decay_rate,\n",
    "    model=model,\n",
    "    initial_tc=initial_tc,\n",
    "    center_x_tc=center_x_tc,\n",
    "    center_y_tc=center_y_tc,\n",
    "    radius_tc=radius_tc,\n",
    "    t_tc=t_tc,\n",
    "    x_tc=x_tc,\n",
    "    y_tc=y_tc,\n",
    "    target=target,\n",
    "    device=device,\n",
    "    n_points=batch_size,\n",
    "    constant_properties=constant_properties,\n",
    "    validation=0.1,\n",
    "    tolerance=0.001,\n",
    "    patience=60,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.shape torch.Size([4000400, 7])\n",
      "t_initial.shape torch.Size([4000400, 1])\n",
      "mesh_ini.shape torch.Size([4000400, 7])\n",
      "C_initial_pred.shape torch.Size([4000400, 2])\n",
      "C_initial_batch.shape torch.Size([4000400, 2])\n",
      "input_pde.shape torch.Size([40004000, 7])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m (\n\u001b[1;32m      2\u001b[0m     model,\n\u001b[1;32m      3\u001b[0m     C_pde_loss_it,\n\u001b[1;32m      4\u001b[0m     C_boundary_loss_it,\n\u001b[1;32m      5\u001b[0m     C_initial_loss_it,\n\u001b[1;32m      6\u001b[0m     C_data_loss_it,\n\u001b[1;32m      7\u001b[0m     val_loss_it,\n\u001b[0;32m----> 8\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 213\u001b[0m, in \u001b[0;36mtrain.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Computing validation loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch-numba-11/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:137\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    136\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch-numba-11/lib/python3.9/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch-numba-11/lib/python3.9/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/.conda/envs/torch-numba-11/lib/python3.9/site-packages/torch/optim/adam.py:202\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 202\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    205\u001b[0m     params_with_grad: List[Tensor] \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[22], line 117\u001b[0m, in \u001b[0;36mtrain.loss_func\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Computing pde loss\u001b[39;00m\n\u001b[1;32m    113\u001b[0m initial, center_x, center_y, radius, t, x, y \u001b[38;5;241m=\u001b[39m generate_training_points(\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_points\n\u001b[1;32m    115\u001b[0m )\n\u001b[0;32m--> 117\u001b[0m predicted_pde \u001b[38;5;241m=\u001b[39m \u001b[43mpde\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenter_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenter_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant_properties\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant_properties\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlambd_nb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant_properties\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant_properties\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_n\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant_properties\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCn_max\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant_properties\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlambd_bn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant_properties\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmi_n\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant_properties\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant_properties\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX_nb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_pde \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(\n\u001b[1;32m    139\u001b[0m     predicted_pde,\n\u001b[1;32m    140\u001b[0m     torch\u001b[38;5;241m.\u001b[39mzeros_like(predicted_pde),\n\u001b[1;32m    141\u001b[0m )\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Computing boundary loss\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[21], line 42\u001b[0m, in \u001b[0;36mpde\u001b[0;34m(model, device, initial, center_x, center_y, radius, t, x, y, cb, lambd_nb, Db, y_n, Cn_max, lambd_bn, mi_n, Dn, X_nb)\u001b[0m\n\u001b[1;32m     22\u001b[0m input_pde \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     23\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m     24\u001b[0m         [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_pde.shape\u001b[39m\u001b[38;5;124m\"\u001b[39m,input_pde\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 42\u001b[0m Cl, Cp \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_pde\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtensor_split(\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m input_pde\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Calculating Cp value\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch-numba-11/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch-numba-11/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/torch-numba-11/lib/python3.9/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/torch-numba-11/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch-numba-11/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/torch-numba-11/lib/python3.9/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "(\n",
    "    model,\n",
    "    C_pde_loss_it,\n",
    "    C_boundary_loss_it,\n",
    "    C_initial_loss_it,\n",
    "    C_data_loss_it,\n",
    "    val_loss_it,\n",
    ") = trainer.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=[18, 9])\n",
    "\n",
    "fig.suptitle(\"Curva de aprendizagem\", fontsize=16)\n",
    "\n",
    "# Plotango 3D\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.set_xlabel(\"iterações\")\n",
    "ax.set_ylabel(\"perda\")\n",
    "ax.plot(\n",
    "    range(len(C_pde_loss_it.cpu().numpy())),\n",
    "    C_pde_loss_it.cpu().numpy(),\n",
    "    label=\"PDE loss\",\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    range(len(C_boundary_loss_it.cpu().numpy())),\n",
    "    C_boundary_loss_it.cpu().numpy(),\n",
    "    label=\"Boundary loss\",\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    range(len(val_loss_it.cpu().numpy())),\n",
    "    val_loss_it.cpu().numpy(),\n",
    "    label=\"Validation loss\",\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    range(len(C_data_loss_it.cpu().numpy())),\n",
    "    C_data_loss_it.cpu().numpy(),\n",
    "    label=\"Data loss\",\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    range(len(C_initial_loss_it.cpu().numpy())),\n",
    "    C_initial_loss_it.cpu().numpy(),\n",
    "    label=\"Initial loss\",\n",
    ")\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=[18, 9])\n",
    "\n",
    "fig.suptitle(\"Curva de aprendizagem\", fontsize=16)\n",
    "\n",
    "# Plotango 3D\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.set_xlabel(\"iterações\")\n",
    "ax.set_ylabel(\"perda\")\n",
    "\n",
    "ax.plot(\n",
    "    range(len(C_initial_loss_it.cpu().numpy())),\n",
    "    C_initial_loss_it.cpu().numpy()\n",
    "    + C_pde_loss_it.cpu().numpy()\n",
    "    + C_boundary_loss_it.cpu().numpy()\n",
    "    + C_data_loss_it.cpu().numpy(),\n",
    "    label=\"PINN loss\",\n",
    ")\n",
    "ax.plot(\n",
    "    range(len(val_loss_it.cpu().numpy())),\n",
    "    val_loss_it.cpu().numpy(),\n",
    "    label=\"Validation loss\",\n",
    ")\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Print model's state_dict\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms state_dict:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(param_tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m.\u001b[39mstate_dict()[param_tensor]\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "torch.save(model.state_dict(), cwd + \"/nn_parameters/\" + arch_str + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "model = generate_model(arch_str).to(device)\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(cwd + \"/nn_parameters/\" + arch_str + \".pt\", weights_only=True)\n",
    ")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fvm_model_parallel import cu_solve_pde\n",
    "import math\n",
    "from numba import cuda\n",
    "\n",
    "speed_up = []\n",
    "\n",
    "for i in range(33):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Definindo número de threads e blocos para cuda\n",
    "\n",
    "    threadsperblock = (size_x, size_y)\n",
    "    blockspergrid_x = math.ceil(size_x / threadsperblock[0])\n",
    "    blockspergrid_y = math.ceil(size_y / threadsperblock[1])\n",
    "    blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "\n",
    "    # Inicializando as matrizes para concentrações de neutrófilos (Cn) e bactérias (Cb)\n",
    "\n",
    "    Cb_buf_0 = cuda.to_device(np.zeros((size_x, size_y)))\n",
    "    Cn_buf_0 = cuda.to_device(np.zeros((size_x, size_y)))\n",
    "\n",
    "    # This extra array is used for synchronization purposes\n",
    "\n",
    "    Cb_buf_1 = cuda.device_array_like(Cb_buf_0)\n",
    "    Cn_buf_1 = cuda.device_array_like(Cn_buf_0)\n",
    "\n",
    "    # Matrizes para armazenar as concentrações em cada passo de tempo\n",
    "    Cb_final_device = cuda.to_device(np.zeros((size_t, size_x, size_y)))\n",
    "    Cn_final_device = cuda.to_device(np.zeros((size_t, size_x, size_y)))\n",
    "\n",
    "    cu_solve_pde[threadsperblock, blockspergrid](\n",
    "        Cb_buf_0,\n",
    "        Cn_buf_0,\n",
    "        Cb_buf_1,\n",
    "        Cn_buf_1,\n",
    "        Cb_final_device,\n",
    "        Cn_final_device,\n",
    "        size_t,\n",
    "        size_x,\n",
    "        size_y,\n",
    "        h,\n",
    "        k,\n",
    "        Db,\n",
    "        Dn,\n",
    "        phi,\n",
    "        cb,\n",
    "        lambd_nb,\n",
    "        mi_n,\n",
    "        lambd_bn,\n",
    "        y_n,\n",
    "        Cn_max,\n",
    "        X_nb,\n",
    "    )\n",
    "\n",
    "    Cb_host = np.empty(shape=Cb_final_device.shape, dtype=Cb_final_device.dtype)\n",
    "    Cb_final_device.copy_to_host(Cb_host)\n",
    "\n",
    "    Cn_host = np.empty(shape=Cn_final_device.shape, dtype=Cn_final_device.dtype)\n",
    "    Cn_final_device.copy_to_host(Cn_host)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    cuda_time = end - start\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    mesh = torch.cat([t_tc, x_tc, y_tc], dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Cl_pinn_device, Cp_pinn_device = model(mesh).split(1, dim=1)\n",
    "\n",
    "    Cl_pinn = Cl_pinn_device.cpu().detach().numpy()\n",
    "    Cp_pinn = Cp_pinn_device.cpu().detach().numpy()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    pinn_time = end - start\n",
    "\n",
    "    speed_up.append(cuda_time / pinn_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_speed_up = np.mean(speed_up)\n",
    "std_speed_up = np.std(speed_up)\n",
    "\n",
    "rmse = np.mean(\n",
    "    [\n",
    "        ((Cl_p[0] - Cl_f) ** 2 + (Cp_p[0] - Cp_f) ** 2) ** 0.5\n",
    "        for Cl_p, Cp_p, Cl_f, Cp_f in zip(\n",
    "            Cl_pinn, Cp_pinn, Cn_fdm.flatten(), Cb_fdm.flatten()\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "max_ae = np.max(\n",
    "    [\n",
    "        [((Cl_p[0] - Cl_f) ** 2) ** 0.5, ((Cp_p[0] - Cp_f) ** 2) ** 0.5]\n",
    "        for Cl_p, Cp_p, Cl_f, Cp_f in zip(\n",
    "            Cl_pinn, Cp_pinn, Cn_fdm.flatten(), Cb_fdm.flatten()\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    \"rmse\": rmse,\n",
    "    \"max_ae\": max_ae,\n",
    "    \"mean_speed_up\": mean_speed_up,\n",
    "    \"std_speed_up\": std_speed_up,\n",
    "    \"Cl_pinn\": Cl_pinn,\n",
    "    \"Cp_pinn\": Cp_pinn,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erro absoluto médio\", rmse)\n",
    "print(\"Erro absoluto máximo\", max_ae)\n",
    "print(\"Speed Up: {} +/-{}\".format(mean_speed_up, std_speed_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cl_pinn_np = Cl_pinn.reshape(size_t, size_x, size_y)\n",
    "Cp_pinn_np = Cp_pinn.reshape(size_t, size_x, size_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(x_dom[0], x_dom[1], num=size_x, endpoint=True)\n",
    "y = np.linspace(y_dom[0], y_dom[1], num=size_y, endpoint=True)\n",
    "t = np.linspace(t_dom[0], t_dom[1], num=size_t, endpoint=True)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "time_plot = np.linspace(0, len(t) - 1, num=5, endpoint=True, dtype=int)\n",
    "\n",
    "fig = plt.figure(figsize=[6 * len(time_plot), 14])\n",
    "\n",
    "fig.suptitle(\"Resposta imunológica a patógenos\", fontsize=16)\n",
    "\n",
    "for i, time_inst in enumerate(time_plot):\n",
    "    # Plotango 3D\n",
    "    ax = fig.add_subplot(4, len(time_plot), i + 1)\n",
    "\n",
    "    vmin = np.min(Cp_pinn_np)\n",
    "    vmax = np.max(Cp_pinn_np)\n",
    "\n",
    "    contour = ax.contourf(\n",
    "        X,\n",
    "        Y,\n",
    "        Cp_pinn_np[time_inst],\n",
    "        cmap=\"jet\",\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Con. de bactérias em t={}\".format(t[time_inst]))\n",
    "    ax.set_xlabel(\"tempo\")\n",
    "    ax.set_ylabel(\"cond. inicial\")\n",
    "    colobar = fig.colorbar(contour, ticks=np.linspace(vmin, vmax, num=5))\n",
    "\n",
    "for i, time_inst in enumerate(time_plot):\n",
    "    # Plotango 3D\n",
    "    ax = fig.add_subplot(4, len(time_plot), i + len(time_plot) + 1)\n",
    "\n",
    "    vmin = np.min(Cl_pinn_np)\n",
    "    vmax = np.max(Cl_pinn_np)\n",
    "\n",
    "    contour = ax.contourf(\n",
    "        X,\n",
    "        Y,\n",
    "        Cl_pinn_np[time_inst],\n",
    "        cmap=\"jet\",\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Con. de bactérias em t={}\".format(t[time_inst]))\n",
    "    ax.set_xlabel(\"tempo\")\n",
    "    ax.set_ylabel(\"cond. inicial\")\n",
    "    colobar = fig.colorbar(contour, ticks=np.linspace(vmin, vmax, num=5))\n",
    "\n",
    "for i, it in enumerate(time_plot):\n",
    "    # Plotango 3D\n",
    "    ax = fig.add_subplot(4, len(time_plot), i + len(time_plot) * 2 + 1)\n",
    "\n",
    "    vmin = np.min(Cb_fdm)\n",
    "    vmax = np.max(Cb_fdm)\n",
    "\n",
    "    contour = ax.contourf(\n",
    "        X,\n",
    "        Y,\n",
    "        Cb_fdm[it],\n",
    "        cmap=\"jet\",\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Con. de bactérias em t={}\".format(t[it]))\n",
    "    ax.set_xlabel(\"tempo\")\n",
    "    ax.set_ylabel(\"cond. inicial\")\n",
    "    colobar = fig.colorbar(contour, ticks=np.linspace(vmin, vmax, num=5))\n",
    "\n",
    "for i, it in enumerate(time_plot):\n",
    "    # Plotango 3D\n",
    "    ax = fig.add_subplot(4, len(time_plot), i + len(time_plot) * 3 + 1)\n",
    "\n",
    "    vmin = np.min(Cn_fdm)\n",
    "    vmax = np.max(Cn_fdm)\n",
    "\n",
    "    contour = ax.contourf(\n",
    "        X,\n",
    "        Y,\n",
    "        Cn_fdm[it],\n",
    "        cmap=\"jet\",\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Con. de bactérias em t={}\".format(t[it]))\n",
    "    ax.set_xlabel(\"tempo\")\n",
    "    ax.set_ylabel(\"cond. inicial\")\n",
    "    colobar = fig.colorbar(contour, ticks=np.linspace(vmin, vmax, num=5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-numba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

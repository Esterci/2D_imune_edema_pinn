{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definições iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "with open(\"control_dicts/constant_properties.json\", \"r\") as openfile:\n",
    "    # Reading from json file\n",
    "    constant_properties = json.load(openfile)\n",
    "\n",
    "Db = constant_properties[\"Db\"]\n",
    "Dn = constant_properties[\"Dn\"]\n",
    "phi = constant_properties[\"phi\"]\n",
    "cb = constant_properties[\"cb\"]\n",
    "lambd_nb = constant_properties[\"lambd_nb\"]\n",
    "mi_n = constant_properties[\"mi_n\"]\n",
    "lambd_bn = constant_properties[\"lambd_bn\"]\n",
    "y_n = constant_properties[\"y_n\"]\n",
    "Cn_max = constant_properties[\"Cn_max\"]\n",
    "X_nb = constant_properties[\"X_nb\"]\n",
    "central_ini_cond = constant_properties[\"central_ini_cond\"]\n",
    "ini_cond_var = constant_properties[\"ini_cond_var\"]\n",
    "\n",
    "# Opening JSON file\n",
    "with open(\"control_dicts/mesh_properties.json\", \"r\") as openfile:\n",
    "    # Reading from json file\n",
    "    mesh_properties = json.load(openfile)\n",
    "\n",
    "h = mesh_properties[\"h\"]\n",
    "k = mesh_properties[\"k\"]\n",
    "x_dom = mesh_properties[\"x_dom\"]\n",
    "y_dom = mesh_properties[\"y_dom\"]\n",
    "t_dom = mesh_properties[\"t_dom\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_infection_site(struct_name):\n",
    "\n",
    "    center_str = (struct_name).split(\"__\")[-2].split(\"(\")[-1].split(\")\")[0].split(\",\")\n",
    "\n",
    "    center = (float(center_str[0]), float(center_str[1]))\n",
    "\n",
    "    radius = float(struct_name.split(\"__\")[-1].split(\"--\")[-1].split(\".pkl\")[0])\n",
    "\n",
    "    return center, radius\n",
    "\n",
    "\n",
    "def read_files(path):\n",
    "    file_list = sorted(glob(path + \"/*\"))\n",
    "\n",
    "    speed_up_list = []\n",
    "    Cb_list = []\n",
    "    Cn_list = []\n",
    "\n",
    "    for file in file_list:\n",
    "\n",
    "        variable = lambda a: a.split(\"/\")[-1].split(\"__\")[0]\n",
    "\n",
    "        if variable(file) == \"Cl\":\n",
    "            Cn_list.append(file)\n",
    "\n",
    "        elif variable(file) == \"Cp\":\n",
    "            Cb_list.append(file)\n",
    "\n",
    "        elif variable(file) == \"speed_up\":\n",
    "            speed_up_list.append(file)\n",
    "\n",
    "    return Cn_list, Cb_list, speed_up_list\n",
    "\n",
    "\n",
    "def change_dim_order(np_array):\n",
    "    # (2, 2, 100001, 21, 21)\n",
    "    sim_shape = np_array.shape\n",
    "\n",
    "    form_array = np.zeros(\n",
    "        (\n",
    "            sim_shape[2],\n",
    "            sim_shape[0],\n",
    "            sim_shape[1],\n",
    "            sim_shape[3],\n",
    "            sim_shape[4],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for i in range(sim_shape[2]):\n",
    "        form_array[i, :, :, :, :] = np_array[:, :, i, :, :]\n",
    "\n",
    "    return form_array\n",
    "\n",
    "\n",
    "def format_array(Cb_list, Cn_list):\n",
    "\n",
    "    for i, (Cb_file, Cn_file) in enumerate(zip(Cb_list, Cn_list)):\n",
    "        with open(Cb_file, \"rb\") as f:\n",
    "            new_Cb = pk.load(f)\n",
    "\n",
    "        with open(Cn_file, \"rb\") as f:\n",
    "            new_Cn = pk.load(f)\n",
    "\n",
    "        sim_shape = new_Cb.shape\n",
    "\n",
    "        if i == 0:\n",
    "            Cb = np.zeros(\n",
    "                (len(Cb_list), sim_shape[0], sim_shape[1], sim_shape[2], sim_shape[3])\n",
    "            )\n",
    "\n",
    "            Cn = np.zeros(\n",
    "                (len(Cn_list), sim_shape[0], sim_shape[1], sim_shape[2], sim_shape[3])\n",
    "            )\n",
    "\n",
    "            center_x = np.zeros(len(Cb_list))\n",
    "\n",
    "            center_y = np.zeros(len(Cb_list))\n",
    "\n",
    "            radius_array = np.zeros(len(Cb_list))\n",
    "\n",
    "        Cb[i, :, :, :, :] = new_Cb\n",
    "\n",
    "        Cn[i, :, :, :, :] = new_Cn\n",
    "\n",
    "        center, radius = get_infection_site(Cb_file)\n",
    "\n",
    "        center_x[i], center_y[i] = center\n",
    "\n",
    "        radius_array[i] = radius\n",
    "\n",
    "    return Cb, Cn, center_x, center_y, radius_array\n",
    "\n",
    "\n",
    "Cn_list, Cb_list, speed_up_list = read_files(\"fvm_sim\")\n",
    "\n",
    "Cb_fvm, Cn_fvm, center_x_array, center_y_array, radius_array = format_array(\n",
    "    Cb_list[:1], Cn_list[:1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps in time = 10001\n",
      "Steps in space_x = 20\n",
      "Steps in space_y = 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_mesh_properties(\n",
    "    x_dom,\n",
    "    y_dom,\n",
    "    t_dom,\n",
    "    h,\n",
    "    k,\n",
    "    central_ini_cond,\n",
    "    ini_cond_var,\n",
    "    n_ini,\n",
    "    verbose=True,\n",
    "):\n",
    "\n",
    "    size_x = int(((x_dom[1] - x_dom[0]) / (h)))\n",
    "    size_y = int(((y_dom[1] - y_dom[0]) / (h)))\n",
    "    size_t = int(((t_dom[1] - t_dom[0]) / (k)) + 1)\n",
    "\n",
    "    initial_cond = np.linspace(\n",
    "        central_ini_cond * (1 - ini_cond_var),\n",
    "        central_ini_cond * (1 + ini_cond_var),\n",
    "        num=n_ini,\n",
    "        endpoint=True,\n",
    "        dtype=np.float16,\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Steps in time = {:d}\\nSteps in space_x = {:d}\\nSteps in space_y = {:d}\\n\".format(\n",
    "                size_t,\n",
    "                size_x,\n",
    "                size_y,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return (size_x, size_y, size_t, initial_cond)\n",
    "\n",
    "\n",
    "size_x, size_y, size_t, initial_cond = get_mesh_properties(\n",
    "    x_dom, y_dom, t_dom, h, k, central_ini_cond, ini_cond_var, Cb_fvm.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_mesh(\n",
    "    t_dom,\n",
    "    x_dom,\n",
    "    y_dom,\n",
    "    size_t,\n",
    "    size_x,\n",
    "    size_y,\n",
    "    center_x_array,\n",
    "    center_y_array,\n",
    "    initial_cond,\n",
    "    radius_array,\n",
    "):\n",
    "    t_np = np.linspace(t_dom[0], t_dom[1], num=size_t, endpoint=False, dtype=np.float32)\n",
    "    x_np = np.linspace(x_dom[0], x_dom[1], num=size_x, endpoint=False, dtype=np.float32)\n",
    "    y_np = np.linspace(y_dom[0], y_dom[1], num=size_y, endpoint=False, dtype=np.float32)\n",
    "    infection_idx = np.linspace(\n",
    "        0, len(center_x_array), num=len(center_x_array), endpoint=False, dtype=np.int32\n",
    "    )\n",
    "\n",
    "    # Change first with second dimension for np.meshgrid match with\n",
    "    # torch.mashgrid and C flattening logic\n",
    "\n",
    "    initial_mesh, infection_mesh, t_mesh, x_mesh, y_mesh = np.meshgrid(\n",
    "        initial_cond, infection_idx, t_np, x_np, y_np\n",
    "    )\n",
    "\n",
    "    center_x_mesh = np.zeros(infection_mesh.ravel().shape)\n",
    "    center_y_mesh = np.zeros(infection_mesh.ravel().shape)\n",
    "    radius_mesh = np.zeros(infection_mesh.ravel().shape)\n",
    "\n",
    "    for i, idx in enumerate(infection_mesh.ravel()):\n",
    "\n",
    "        center_x_mesh[i] = center_x_array[idx]\n",
    "        center_y_mesh[i] = center_y_array[idx]\n",
    "        radius_mesh[i] = radius_array[idx]\n",
    "\n",
    "    return (\n",
    "        initial_mesh,\n",
    "        center_x_mesh,\n",
    "        center_y_mesh,\n",
    "        radius_mesh,\n",
    "        t_mesh,\n",
    "        x_mesh,\n",
    "        y_mesh,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocates_training_mesh(\n",
    "    t_dom,\n",
    "    x_dom,\n",
    "    y_dom,\n",
    "    size_t,\n",
    "    size_x,\n",
    "    size_y,\n",
    "    center_x_array,\n",
    "    center_y_array,\n",
    "    initial_cond,\n",
    "    radius_array,\n",
    "    Cb_fvm,\n",
    "    Cn_fvm,\n",
    "):\n",
    "\n",
    "    (\n",
    "        initial_mesh,\n",
    "        center_x_mesh,\n",
    "        center_y_mesh,\n",
    "        radius_mesh,\n",
    "        t_mesh,\n",
    "        x_mesh,\n",
    "        y_mesh,\n",
    "    ) = create_input_mesh(\n",
    "        t_dom,\n",
    "        x_dom,\n",
    "        y_dom,\n",
    "        size_t,\n",
    "        size_x,\n",
    "        size_y,\n",
    "        center_x_array,\n",
    "        center_y_array,\n",
    "        initial_cond,\n",
    "        radius_array,\n",
    "    )\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "\n",
    "    print(\"device:\", device)\n",
    "\n",
    "    initial_tc = (\n",
    "        torch.tensor(initial_mesh, dtype=torch.float16)\n",
    "        .reshape(-1, 1)\n",
    "        .requires_grad_(True)\n",
    "    )\n",
    "\n",
    "    center_x_tc = (\n",
    "        torch.tensor(center_x_mesh, dtype=torch.float16)\n",
    "        .reshape(-1, 1)\n",
    "        .requires_grad_(True)\n",
    "    )\n",
    "\n",
    "    center_y_tc = (\n",
    "        torch.tensor(center_y_mesh, dtype=torch.float16)\n",
    "        .reshape(-1, 1)\n",
    "        .requires_grad_(True)\n",
    "    )\n",
    "\n",
    "    radius_tc = (\n",
    "        torch.tensor(radius_mesh, dtype=torch.float16)\n",
    "        .reshape(-1, 1)\n",
    "        .requires_grad_(True)\n",
    "    )\n",
    "\n",
    "    t_tc = (\n",
    "        torch.tensor(t_mesh, dtype=torch.float16)\n",
    "        .reshape(-1, 1)\n",
    "        .requires_grad_(True)\n",
    "    )\n",
    "\n",
    "    x_tc = (\n",
    "        torch.tensor(x_mesh, dtype=torch.float16)\n",
    "        .reshape(-1, 1)\n",
    "        .requires_grad_(True)\n",
    "    )\n",
    "\n",
    "    y_tc = (\n",
    "        torch.tensor(y_mesh, dtype=torch.float16)\n",
    "        .reshape(-1, 1)\n",
    "        .requires_grad_(True)\n",
    "    )\n",
    "\n",
    "    target = torch.tensor(\n",
    "        np.hstack((Cn_fvm.reshape(-1, 1), Cb_fvm.reshape(-1, 1))), dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        initial_tc,\n",
    "        center_x_tc,\n",
    "        center_y_tc,\n",
    "        radius_tc,\n",
    "        t_tc,\n",
    "        x_tc,\n",
    "        y_tc,\n",
    "        target,\n",
    "        device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "(initial_tc, center_x_tc, center_y_tc, radius_tc, t_tc, x_tc, y_tc, target, device) = (\n",
    "    allocates_training_mesh(\n",
    "        t_dom,\n",
    "        x_dom,\n",
    "        y_dom,\n",
    "        size_t,\n",
    "        size_x,\n",
    "        size_y,\n",
    "        center_x_array,\n",
    "        center_y_array,\n",
    "        initial_cond,\n",
    "        radius_array,\n",
    "        Cb_fvm,\n",
    "        Cn_fvm,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archtecture handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_dict = {\n",
    "    \"Elu\": nn.ELU,\n",
    "    \"LeakyReLU\": nn.LeakyReLU,\n",
    "    \"Sigmoid\": nn.Sigmoid,\n",
    "    \"Softplus\": nn.Softplus,\n",
    "    \"Tanh\": nn.Tanh,\n",
    "    \"Linear\": nn.Linear,\n",
    "    \"ReLU\": nn.ReLU,\n",
    "    \"RReLU\": nn.RReLU,\n",
    "    \"SELU\": nn.SELU,\n",
    "    \"CELU\": nn.CELU,\n",
    "    \"GELU\": nn.GELU,\n",
    "    \"SiLU\": nn.SiLU,\n",
    "    \"GLU\": nn.GLU,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_str = \"Tanh--32__Tanh--32__Tanh--32__GELU--32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(arch_str):\n",
    "    hidden_layers = arch_str.split(\"__\")\n",
    "\n",
    "    modules = []\n",
    "\n",
    "    for params in hidden_layers:\n",
    "        if len(params) != 0:\n",
    "            activation, out_neurons = params.split(\"--\")\n",
    "\n",
    "            if len(modules) == 0:\n",
    "                if activation == \"Linear\":\n",
    "                    modules.append(\n",
    "                        activation_dict[activation](7, int(out_neurons)).half()\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    modules.append(nn.Linear(7, int(out_neurons)).half())\n",
    "                    modules.append(activation_dict[activation]().half())\n",
    "\n",
    "            else:\n",
    "                if activation == \"Linear\":\n",
    "                    modules.append(\n",
    "                        activation_dict[activation](\n",
    "                            int(in_neurons), int(out_neurons)\n",
    "                        ).half()\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    modules.append(nn.Linear(int(in_neurons), int(out_neurons)).half())\n",
    "                    modules.append(activation_dict[activation]().half())\n",
    "\n",
    "            in_neurons = out_neurons\n",
    "\n",
    "    modules.append(nn.Linear(int(in_neurons), 2).half())\n",
    "\n",
    "    return nn.Sequential(*modules)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.zeros_(m.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=7, out_features=32, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (5): Tanh()\n",
      "  (6): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (7): GELU(approximate='none')\n",
      "  (8): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = generate_model(arch_str).to(device).apply(init_weights)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_torch(dataset):\n",
    "    with torch.no_grad():\n",
    "        dt_min = torch.min(dataset, 0).values\n",
    "        dt_max = torch.max(dataset, 0).values\n",
    "        normalized = (dataset - dt_min) / (dt_max - dt_min)\n",
    "\n",
    "    return normalized.requires_grad_(True), dt_min, dt_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data_input(data_input, steps):\n",
    "    with torch.no_grad():\n",
    "        dataset = data_input.reshape(steps, steps, 2)\n",
    "        normalized = torch.zeros_like(dataset)\n",
    "        for i in range(len(dataset)):\n",
    "            dt_min = torch.min(dataset[i], 0).values\n",
    "            dt_max = torch.max(dataset[i], 0).values\n",
    "            normalized[i] = (dataset[i] - dt_min) / (dt_max - dt_min)\n",
    "\n",
    "    return normalized.reshape((steps) * (steps), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(dataset, dt_min, dt_max):\n",
    "    return (dt_max - dt_min) * dataset + dt_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(initial, center_x, center_y, radius, t, x, y, target):\n",
    "    Data_num = np.arange(x.shape[0])\n",
    "    np.random.shuffle(Data_num)\n",
    "\n",
    "    return (\n",
    "        initial[Data_num],\n",
    "        center_x[Data_num],\n",
    "        center_y[Data_num],\n",
    "        radius[Data_num],\n",
    "        t[Data_num],\n",
    "        x[Data_num],\n",
    "        y[Data_num],\n",
    "        target[Data_num],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(\n",
    "    initial,\n",
    "    center_x,\n",
    "    center_y,\n",
    "    radius,\n",
    "    t,\n",
    "    x,\n",
    "    y,\n",
    "    target,\n",
    "    device,\n",
    "    test_size=0.5,\n",
    "    shuffle=True,\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        if shuffle:\n",
    "            initial, center_x, center_y, radius, t, x, y, target = shuffle_data(\n",
    "                initial, center_x, center_y, radius, t, x, y, target\n",
    "            )\n",
    "        if test_size < 1:\n",
    "            train_ratio = len(x) - int(len(x) * test_size)\n",
    "            initial_train, initial_test = initial[:train_ratio], initial[train_ratio:]\n",
    "            center_x_train, center_x_test = (\n",
    "                center_x[:train_ratio],\n",
    "                center_x[train_ratio:],\n",
    "            )\n",
    "            center_y_train, center_y_test = (\n",
    "                center_y[:train_ratio],\n",
    "                center_y[train_ratio:],\n",
    "            )\n",
    "            radius_train, radius_test = radius[:train_ratio], radius[train_ratio:]\n",
    "            t_train, t_test = t[:train_ratio], t[train_ratio:]\n",
    "            x_train, x_test = x[:train_ratio], x[train_ratio:]\n",
    "            y_train, y_test = y[:train_ratio], y[train_ratio:]\n",
    "            target_train, target_test = target[:train_ratio], target[train_ratio:]\n",
    "            return (\n",
    "                initial_train.requires_grad_(True).to(device),\n",
    "                initial_test.requires_grad_(True).to(device),\n",
    "                center_x_train.requires_grad_(True).to(device),\n",
    "                center_x_test.requires_grad_(True).to(device),\n",
    "                center_y_train.requires_grad_(True).to(device),\n",
    "                center_y_test.requires_grad_(True).to(device),\n",
    "                radius_train.requires_grad_(True).to(device),\n",
    "                radius_test.requires_grad_(True).to(device),\n",
    "                t_train.requires_grad_(True).to(device),\n",
    "                t_test.requires_grad_(True).to(device),\n",
    "                x_train.requires_grad_(True).to(device),\n",
    "                x_test.requires_grad_(True).to(device),\n",
    "                y_train.requires_grad_(True).to(device),\n",
    "                y_test.requires_grad_(True).to(device),\n",
    "                target_train.requires_grad_(True).to(device),\n",
    "                target_test.requires_grad_(True).to(device),\n",
    "            )\n",
    "        elif test_size in range(1, len(x)):\n",
    "            initial_train, initial_test = initial[test_size:], initial[:test_size]\n",
    "            center_x_train, center_x_test = (\n",
    "                center_x[test_size:],\n",
    "                center_x[:test_size],\n",
    "            )\n",
    "            center_y_train, center_y_test = (\n",
    "                center_y[test_size:],\n",
    "                center_y[:test_size],\n",
    "            )\n",
    "            radius_train, radius_test = radius[test_size:], radius[:test_size]\n",
    "            t_train, t_test = t[test_size:], t[:test_size]\n",
    "            x_train, x_test = x[test_size:], x[:test_size]\n",
    "            y_train, y_test = y[test_size:], y[:test_size]\n",
    "            target_train, target_test = target[test_size:], target[:test_size]\n",
    "            return (\n",
    "                initial_train.requires_grad_(True).to(device),\n",
    "                initial_test.requires_grad_(True).to(device),\n",
    "                center_x_train.requires_grad_(True).to(device),\n",
    "                center_x_test.requires_grad_(True).to(device),\n",
    "                center_y_train.requires_grad_(True).to(device),\n",
    "                center_y_test.requires_grad_(True).to(device),\n",
    "                radius_train.requires_grad_(True).to(device),\n",
    "                radius_test.requires_grad_(True).to(device),\n",
    "                t_train.requires_grad_(True).to(device),\n",
    "                t_test.requires_grad_(True).to(device),\n",
    "                x_train.requires_grad_(True).to(device),\n",
    "                x_test.requires_grad_(True).to(device),\n",
    "                y_train.requires_grad_(True).to(device),\n",
    "                y_test.requires_grad_(True).to(device),\n",
    "                target_train.requires_grad_(True).to(device),\n",
    "                target_test.requires_grad_(True).to(device),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_points(num_points):\n",
    "    initial = torch.rand(num_points, 1, dtype=torch.float16) * (0.6 - 0.4) + 0.4\n",
    "    center_x = torch.rand(num_points, 1, dtype=torch.float16)\n",
    "    center_y = torch.rand(num_points, 1, dtype=torch.float16)\n",
    "    radius = torch.rand(num_points, 1, dtype=torch.float16) * (0.2 - 0.1) + 0.1\n",
    "    t = torch.rand(num_points, 1, dtype=torch.float16) * 10\n",
    "    x = torch.rand(num_points, 1, dtype=torch.float16)\n",
    "    y = torch.rand(num_points, 1, dtype=torch.float16)\n",
    "\n",
    "    return (\n",
    "        initial.requires_grad_(True).to(device),\n",
    "        center_x.requires_grad_(True).to(device),\n",
    "        center_y.requires_grad_(True).to(device),\n",
    "        radius.requires_grad_(True).to(device),\n",
    "        t.requires_grad_(True).to(device),\n",
    "        x.requires_grad_(True).to(device),\n",
    "        y.requires_grad_(True).to(device),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_boundary_points(num_points):\n",
    "    x_boundary = torch.tensor([0.0, 1], dtype=torch.float16).repeat(num_points // 2, 1)\n",
    "    y_boundary = torch.rand(num_points, dtype=torch.float16)\n",
    "\n",
    "    if torch.rand(1) > 0.5:\n",
    "        x_boundary, y_boundary = y_boundary, x_boundary\n",
    "        n = torch.tensor([[0.0, -1.0], [0.0, 1.0]], dtype=torch.float16).repeat(\n",
    "            num_points // 2, 1\n",
    "        )\n",
    "    else:\n",
    "        n = torch.tensor([[-1.0, 0.0], [1.0, 0.0]], dtype=torch.float16).repeat(\n",
    "            num_points // 2, 1\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        x_boundary.view(-1, 1).requires_grad_(True).to(device),\n",
    "        y_boundary.view(-1, 1).requires_grad_(True).to(device),\n",
    "        n.requires_grad_(True).to(device),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_condition_points(data_input):\n",
    "\n",
    "    initial_tc = data_input[:,0]\n",
    "    center_x_tc= data_input[:,1]\n",
    "    center_y_tc= data_input[:,2]\n",
    "    radius_tc= data_input[:,3]\n",
    "    x_tc= data_input[:,5]\n",
    "    y_tc= data_input[:,6]\n",
    "\n",
    "    # Calculate squared distances from each point to the circle centers\n",
    "    squared_distances = (x_tc - center_x_tc) ** 2 + (y_tc - center_y_tc) ** 2\n",
    "\n",
    "    # Create a mask for points inside the circle\n",
    "    inside_circle_mask = squared_distances <= radius_tc**2\n",
    "\n",
    "    # Initialize the tensor and set the values for points inside the circle\n",
    "    C_init = torch.zeros((len(x_tc), 2),dtype=torch.float16)\n",
    "    C_init[:, 1] = inside_circle_mask.ravel() * initial_tc.ravel()\n",
    "\n",
    "    return C_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_condition(\n",
    "    model, device, initial, center_x, center_y, radius, t_b, x_b, y_b, n, Dn, X_nb, Db\n",
    "):\n",
    "\n",
    "    input_boundary = (\n",
    "        torch.cat(\n",
    "            [\n",
    "                initial,\n",
    "                center_x,\n",
    "                center_y,\n",
    "                radius,\n",
    "                t_b,\n",
    "                x_b,\n",
    "                y_b,\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        .to(device)\n",
    "        .requires_grad_(True)\n",
    "    )\n",
    "\n",
    "    Cp, Cl = model(input_boundary).tensor_split(2, dim=1)\n",
    "\n",
    "    del input_boundary\n",
    "    nx, ny = n.tensor_split(2, dim=1)\n",
    "\n",
    "    if nx[0].item() != 0:\n",
    "        dCp_dx = torch.autograd.grad(\n",
    "            Cp,\n",
    "            x_b,\n",
    "            grad_outputs=torch.ones_like(Cp),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )\n",
    "\n",
    "        dCl_dx = torch.autograd.grad(\n",
    "            Cl,\n",
    "            x_b,\n",
    "            grad_outputs=torch.ones_like(Cl),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )\n",
    "\n",
    "        Cl_boundary = torch.mul(\n",
    "            ((Dn * dCl_dx[0]) - X_nb * torch.mul(Cl, dCp_dx[0])), nx\n",
    "        )\n",
    "\n",
    "        Cp_boundary = torch.mul((Db * dCp_dx[0]), nx)\n",
    "\n",
    "        return torch.cat([Cl_boundary, Cp_boundary], dim=1)\n",
    "\n",
    "    else:\n",
    "        dCp_dy = torch.autograd.grad(\n",
    "            Cp,\n",
    "            y_b,\n",
    "            grad_outputs=torch.ones_like(Cp),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )\n",
    "\n",
    "        dCl_dy = torch.autograd.grad(\n",
    "            Cl,\n",
    "            y_b,\n",
    "            grad_outputs=torch.ones_like(Cl),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )\n",
    "\n",
    "        Cl_boundary = torch.mul(\n",
    "            ((Dn * dCl_dy[0]) - X_nb * torch.mul(Cl, dCp_dy[0])), ny\n",
    "        )\n",
    "\n",
    "        Cp_boundary = torch.mul((Db * dCp_dy[0]), ny)\n",
    "\n",
    "        return torch.cat([Cl_boundary, Cp_boundary], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde(\n",
    "    model,\n",
    "    device,\n",
    "    initial,\n",
    "    center_x,\n",
    "    center_y,\n",
    "    radius,\n",
    "    t,\n",
    "    x,\n",
    "    y,\n",
    "    cb,\n",
    "    lambd_nb,\n",
    "    Db,\n",
    "    y_n,\n",
    "    Cn_max,\n",
    "    lambd_bn,\n",
    "    mi_n,\n",
    "    Dn,\n",
    "    X_nb,\n",
    "):\n",
    "\n",
    "    Cl, Cp = model(\n",
    "        torch.cat(\n",
    "            [\n",
    "                initial,\n",
    "                center_x,\n",
    "                center_y,\n",
    "                radius,\n",
    "                t,\n",
    "                x,\n",
    "                y,\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "    ).tensor_split(2, dim=1)\n",
    "\n",
    "    # Calculating Cp value\n",
    "\n",
    "    dCp_dx, dCp_dy = torch.autograd.grad(\n",
    "        Cp,\n",
    "        [x, y],\n",
    "        grad_outputs=torch.ones_like(Cp),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )\n",
    "\n",
    "    dCp_dx_2 = torch.autograd.grad(\n",
    "        dCp_dx,\n",
    "        x,\n",
    "        grad_outputs=torch.ones_like(dCp_dx),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    dCp_dy_2 = torch.autograd.grad(\n",
    "        dCp_dy,\n",
    "        y,\n",
    "        grad_outputs=torch.ones_like(dCp_dy),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    dCp_dt = torch.autograd.grad(\n",
    "        Cp,\n",
    "        t,\n",
    "        grad_outputs=torch.ones_like(Cp),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    qb = cb * Cp\n",
    "    rb = lambd_nb * torch.mul(Cl, Cp)\n",
    "\n",
    "    Cp_eq = Db * (dCp_dx_2 + dCp_dy_2) - rb + qb - dCp_dt\n",
    "\n",
    "    # Calculating Cl value\n",
    "\n",
    "    dCl_dx, dCl_dy = torch.autograd.grad(\n",
    "        Cl,\n",
    "        [x, y],\n",
    "        grad_outputs=torch.ones_like(Cl),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )\n",
    "\n",
    "    dCl_dx_2 = torch.autograd.grad(\n",
    "        dCl_dx,\n",
    "        x,\n",
    "        grad_outputs=torch.ones_like(dCl_dx),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    dCl_dy_2 = torch.autograd.grad(\n",
    "        dCl_dy,\n",
    "        y,\n",
    "        grad_outputs=torch.ones_like(dCl_dy),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    dCl_dt = torch.autograd.grad(\n",
    "        Cl,\n",
    "        t,\n",
    "        grad_outputs=torch.ones_like(Cl),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    qn = y_n * torch.mul(Cp, (Cn_max - Cl))\n",
    "    rn = lambd_bn * torch.mul(Cl, Cp) + mi_n * Cl\n",
    "\n",
    "    Cl_eq = (\n",
    "        Dn * (dCl_dx_2 + dCl_dy_2)\n",
    "        - X_nb\n",
    "        * (\n",
    "            (torch.mul(dCl_dx, dCp_dx) + torch.mul(Cl, dCp_dx_2))\n",
    "            + (torch.mul(dCl_dy, dCp_dy) + torch.mul(Cl, dCp_dy_2))\n",
    "        )\n",
    "        - rn\n",
    "        + qn\n",
    "    ) - dCl_dt\n",
    "\n",
    "    return torch.cat([Cl_eq, Cp_eq], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_epochs,\n",
    "        batch_size,\n",
    "        decay_rate,\n",
    "        model,\n",
    "        initial_tc,\n",
    "        center_x_tc,\n",
    "        center_y_tc,\n",
    "        radius_tc,\n",
    "        t_tc,\n",
    "        x_tc,\n",
    "        y_tc,\n",
    "        target,\n",
    "        device,\n",
    "        n_points,\n",
    "        constant_properties,\n",
    "        norm_weights=None,\n",
    "        validation=None,\n",
    "        tolerance=None,\n",
    "        patience=10,\n",
    "    ):\n",
    "\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.decay_rate = decay_rate\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.n_points = n_points\n",
    "        self.constant_properties = constant_properties\n",
    "        self.norm_weights = norm_weights\n",
    "        self.validation = validation\n",
    "        self.tolerance = tolerance\n",
    "        self.patience = patience\n",
    "\n",
    "        for i, inp in enumerate(\n",
    "            [\n",
    "                initial_tc,\n",
    "                center_x_tc,\n",
    "                center_y_tc,\n",
    "                radius_tc,\n",
    "                t_tc,\n",
    "                x_tc,\n",
    "                y_tc,\n",
    "                target,\n",
    "            ]\n",
    "        ):\n",
    "            if torch.isnan(inp).any():\n",
    "                print(\"NaN detected in {i}\")\n",
    "\n",
    "        if self.validation:\n",
    "            (\n",
    "                self.initial_train,\n",
    "                self.initial_test,\n",
    "                self.center_x_train,\n",
    "                self.center_x_test,\n",
    "                self.center_y_train,\n",
    "                self.center_y_test,\n",
    "                self.radius_train,\n",
    "                self.radius_test,\n",
    "                self.t_train,\n",
    "                self.t_test,\n",
    "                self.x_train,\n",
    "                self.x_test,\n",
    "                self.y_train,\n",
    "                self.y_test,\n",
    "                self.target_train,\n",
    "                self.target_test,\n",
    "            ) = train_test_split(\n",
    "                initial_tc,\n",
    "                center_x_tc,\n",
    "                center_y_tc,\n",
    "                radius_tc,\n",
    "                t_tc,\n",
    "                x_tc,\n",
    "                y_tc,\n",
    "                target,\n",
    "                device,\n",
    "                test_size=self.validation,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            self.initial_train = initial_tc.to(device)\n",
    "            self.initial_test = None\n",
    "            self.center_x_train = center_x_tc.to(device)\n",
    "            self.center_x_test = None\n",
    "            self.center_y_train = center_y_tc.to(device)\n",
    "            self.center_y_test = None\n",
    "            self.radius_train = radius_tc.to(device)\n",
    "            self.radius_test = None\n",
    "            self.t_train = t_tc.to(device)\n",
    "            self.t_test = None\n",
    "            self.x_train = x_tc.to(device)\n",
    "            self.x_test = None\n",
    "            self.y_train = y_tc.to(device)\n",
    "            self.y_test = None\n",
    "            self.target_train = target.to(device)\n",
    "            self.target_test = None\n",
    "\n",
    "        self.test_data = (\n",
    "            torch.cat(\n",
    "                [\n",
    "                    self.initial_test,\n",
    "                    self.center_x_test,\n",
    "                    self.center_y_test,\n",
    "                    self.radius_test,\n",
    "                    self.t_test,\n",
    "                    self.x_test,\n",
    "                    self.y_test,\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "            .requires_grad_(True)\n",
    "            .to(device)\n",
    "        )\n",
    "\n",
    "        pass\n",
    "\n",
    "    def loss_func(\n",
    "        self,\n",
    "    ):\n",
    "        self.batch = torch.cat(\n",
    "            [\n",
    "                self.initial_train,\n",
    "                self.center_x_train,\n",
    "                self.center_y_train,\n",
    "                self.radius_train,\n",
    "                self.t_train,\n",
    "                self.x_train,\n",
    "                self.y_train,\n",
    "            ],\n",
    "            dim=1,\n",
    "        )[self.i : self.i + self.batch_size, :]\n",
    "\n",
    "        C_initial_batch = initial_condition_points(self.batch).to(self.device)\n",
    "\n",
    "        # Computing intial loss\n",
    "        t_initial = torch.zeros((self.batch.shape[0], 1), dtype=torch.float16).to(\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        mesh_ini = torch.cat(\n",
    "            [self.batch[:, :5], t_initial, self.batch[:, 6:]],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        C_initial_pred = self.model(mesh_ini)\n",
    "\n",
    "        self.loss_initial = self.criterion(C_initial_batch, C_initial_pred)\n",
    "\n",
    "        if torch.isnan(self.batch).any():\n",
    "            print(\"NaN detected in self.batch\")\n",
    "\n",
    "        if torch.isnan(C_initial_batch).any():\n",
    "            print(\"NaN detected in C_initial_batch\")\n",
    "\n",
    "        if torch.isnan(t_initial).any():\n",
    "            print(\"NaN detected in t_initial\")\n",
    "\n",
    "        if torch.isnan(mesh_ini).any():\n",
    "            print(\"NaN detected in mesh_ini\")\n",
    "\n",
    "        if torch.isnan(C_initial_pred).any():\n",
    "            print(\"NaN detected in C_initial_pred\")\n",
    "\n",
    "        if torch.isnan(self.loss_initial).any():\n",
    "            print(\"NaN detected in self.loss_initial\")\n",
    "\n",
    "\n",
    "        # Computing pde loss\n",
    "\n",
    "        initial, center_x, center_y, radius, t, x, y = generate_training_points(\n",
    "            self.n_points\n",
    "        )\n",
    "\n",
    "        predicted_pde = pde(\n",
    "            self.model,\n",
    "            self.device,\n",
    "            initial,\n",
    "            center_x,\n",
    "            center_y,\n",
    "            radius,\n",
    "            t,\n",
    "            x,\n",
    "            y,\n",
    "            self.constant_properties[\"cb\"],\n",
    "            self.constant_properties[\"lambd_nb\"],\n",
    "            self.constant_properties[\"Db\"],\n",
    "            self.constant_properties[\"y_n\"],\n",
    "            self.constant_properties[\"Cn_max\"],\n",
    "            self.constant_properties[\"lambd_bn\"],\n",
    "            self.constant_properties[\"mi_n\"],\n",
    "            self.constant_properties[\"Dn\"],\n",
    "            self.constant_properties[\"X_nb\"],\n",
    "        )\n",
    "\n",
    "        self.loss_pde = self.criterion(\n",
    "            predicted_pde,\n",
    "            torch.zeros_like(predicted_pde),\n",
    "        )\n",
    "\n",
    "        if torch.isnan(initial).any():\n",
    "            print(\"NaN detected in initial\")\n",
    "\n",
    "        if torch.isnan(center_x).any():\n",
    "            print(\"NaN detected in center_x\")\n",
    "\n",
    "        if torch.isnan(center_y).any():\n",
    "            print(\"NaN detected in center_y\")\n",
    "\n",
    "        if torch.isnan(radius).any():\n",
    "            print(\"NaN detected in radius\")\n",
    "\n",
    "        if torch.isnan(t).any():\n",
    "            print(\"NaN detected in t\")\n",
    "\n",
    "        if torch.isnan(x).any():\n",
    "            print(\"NaN detected in x\")\n",
    "\n",
    "        if torch.isnan(y).any():\n",
    "            print(\"NaN detected in y\")\n",
    "\n",
    "        if torch.isnan(predicted_pde).any():\n",
    "            print(\"NaN detected in predicted_pde\")\n",
    "\n",
    "        if torch.isnan(self.loss_pde).any():\n",
    "            print(\"NaN detected in self.loss_pde\")\n",
    "            \n",
    "        # Computing boundary loss\n",
    "\n",
    "        x_bnd, y_bnd, n_bnd = generate_boundary_points(self.n_points)\n",
    "\n",
    "        predicted_boundary = boundary_condition(\n",
    "            self.model,\n",
    "            self.device,\n",
    "            initial,\n",
    "            center_x,\n",
    "            center_y,\n",
    "            radius,\n",
    "            t,\n",
    "            x_bnd,\n",
    "            y_bnd,\n",
    "            n_bnd,\n",
    "            self.constant_properties[\"Dn\"],\n",
    "            self.constant_properties[\"X_nb\"],\n",
    "            self.constant_properties[\"Db\"],\n",
    "        )\n",
    "\n",
    "        self.loss_boundary = self.criterion(\n",
    "            predicted_boundary,\n",
    "            torch.zeros_like(predicted_boundary),\n",
    "        )\n",
    "\n",
    "        if torch.isnan(initial).any():\n",
    "            print(\"NaN detected in initial\")\n",
    "        if torch.isnan(center_x).any():\n",
    "            print(\"NaN detected in center_x\")\n",
    "        if torch.isnan(center_y).any():\n",
    "            print(\"NaN detected in center_y\")\n",
    "        if torch.isnan(radius).any():\n",
    "            print(\"NaN detected in radius\")\n",
    "        if torch.isnan(t).any():\n",
    "            print(\"NaN detected in t\")\n",
    "        if torch.isnan(x_bnd).any():\n",
    "            print(\"NaN detected in x_bnd\")\n",
    "        if torch.isnan(y_bnd).any():\n",
    "            print(\"NaN detected in y_bnd\")\n",
    "\n",
    "\n",
    "        # Computing data loss\n",
    "\n",
    "        C_pred = self.model(self.batch.to(device))\n",
    "\n",
    "        self.loss_data = self.criterion(\n",
    "            C_pred, self.target_train[self.i : self.i + self.batch_size, :]\n",
    "        )\n",
    "\n",
    "        if torch.isnan(C_pred).any():\n",
    "            print(\"NaN detected in C_pred\")\n",
    "\n",
    "        del C_pred\n",
    "\n",
    "        print(\n",
    "            self.loss_initial.item(),\n",
    "            self.loss_pde.item(),\n",
    "            self.loss_boundary.item(),\n",
    "            self.loss_data.item(),\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            10 * self.loss_initial\n",
    "            + self.loss_pde\n",
    "            + self.loss_boundary\n",
    "            + self.loss_data * 10\n",
    "        )\n",
    "\n",
    "    def execute(\n",
    "        self,\n",
    "    ):\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "        dt_min, dt_max = self.norm_weights if self.norm_weights else (0, 1)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-7)\n",
    "        self.lr_scheduler = optim.lr_scheduler.ExponentialLR(\n",
    "            optimizer=self.optimizer, gamma=self.decay_rate\n",
    "        )\n",
    "        C_pde_loss_it = torch.zeros(self.n_epochs)\n",
    "        C_data_loss_it = torch.zeros(self.n_epochs)\n",
    "        C_boundary_loss_it = torch.zeros(self.n_epochs)\n",
    "        C_initial_loss_it = torch.zeros(self.n_epochs)\n",
    "        val_loss_it = torch.zeros(self.n_epochs)\n",
    "\n",
    "        patience_count = 0\n",
    "        val_loss = torch.tensor([1000])\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            for bt, self.i in enumerate(range(0, len(self.x_train), self.batch_size)):\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                loss = self.loss_func()\n",
    "\n",
    "                if torch.isnan(loss).any():\n",
    "                    print(\"⚠ NaN detected in loss\")\n",
    "                loss.backward()\n",
    "                \n",
    "                for name, param in self.model.named_parameters():\n",
    "                    if param.grad is not None:\n",
    "                        if torch.isnan(param.grad).any():\n",
    "                            print(f\"❌ NaN detected in gradients of {name}\")\n",
    "                        if torch.isinf(param.grad).any():\n",
    "                            print(f\"⚠ Inf detected in gradients of {name}\")\n",
    "                            \n",
    "                self.optimizer.step()\n",
    "\n",
    "                if ((bt + 1) % 1) == 0 or (bt == 0):\n",
    "                    print(\n",
    "                        f\"    Finished batch {bt+1}, [{self.i}, ...,{self.i + self.batch_size}] \"\n",
    "                    )\n",
    "                    \n",
    "            for name, param in self.model.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    if torch.isnan(param.grad).any():\n",
    "                        print(f\"❌ NaN detected in gradients of {name}\")\n",
    "                    if torch.isinf(param.grad).any():\n",
    "                        print(f\"⚠ Inf detected in gradients of {name}\")\n",
    "\n",
    "            self.lr_scheduler.step()\n",
    "\n",
    "            # Computing validation loss\n",
    "\n",
    "            if self.validation:\n",
    "                with torch.no_grad():\n",
    "                    val_old = val_loss\n",
    "                    val_loss = self.criterion(\n",
    "                        self.target_test, self.model(self.test_data)\n",
    "                    )\n",
    "                    if torch.isnan(val_loss).any():\n",
    "                        print(\"⚠ NaN detected in val_loss\")\n",
    "\n",
    "            C_pde_loss_it[epoch] = self.loss_pde.item()\n",
    "            C_boundary_loss_it[epoch] = self.loss_boundary.item()\n",
    "            C_initial_loss_it[epoch] = self.loss_initial.item()\n",
    "            C_data_loss_it[epoch] = self.loss_data.item()\n",
    "            val_loss_it[epoch] = val_loss.item() if self.validation else 0\n",
    "\n",
    "            if ((epoch + 1) % 100) == 0 or (epoch == 0):\n",
    "                print(\n",
    "                    f\"Finished epoch {epoch+1}, latest loss {self.loss}, validation loss {val_loss.item()}\"\n",
    "                    if self.validation\n",
    "                    else f\"Finished epoch {epoch+1}, latest loss {self.loss}\"\n",
    "                )\n",
    "\n",
    "            if self.tolerance:\n",
    "\n",
    "                if (\n",
    "                    abs(val_old.item() - val_loss.item()) / val_old.item()\n",
    "                    < self.tolerance\n",
    "                ):\n",
    "                    patience_count += 1\n",
    "\n",
    "                else:\n",
    "                    patience_count = 0\n",
    "\n",
    "                if patience_count >= self.patience:\n",
    "\n",
    "                    C_pde_loss_it = C_pde_loss_it[:epoch]\n",
    "                    C_boundary_loss_it = C_boundary_loss_it[:epoch]\n",
    "                    C_initial_loss_it = C_initial_loss_it[:epoch]\n",
    "                    C_data_loss_it = C_data_loss_it[:epoch]\n",
    "                    val_loss_it = val_loss_it[:epoch]\n",
    "\n",
    "                    print(\"Early break!\")\n",
    "\n",
    "                    break\n",
    "\n",
    "        return (\n",
    "            self.model,\n",
    "            C_pde_loss_it,\n",
    "            C_boundary_loss_it,\n",
    "            C_initial_loss_it,\n",
    "            C_data_loss_it,\n",
    "            val_loss_it,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_rate = 0.9985\n",
    "n_epochs = 1\n",
    "batch_size = 36000\n",
    "\n",
    "trainer = train(\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    decay_rate=decay_rate,\n",
    "    model=model,\n",
    "    initial_tc=initial_tc,\n",
    "    center_x_tc=center_x_tc,\n",
    "    center_y_tc=center_y_tc,\n",
    "    radius_tc=radius_tc,\n",
    "    t_tc=t_tc,\n",
    "    x_tc=x_tc,\n",
    "    y_tc=y_tc,\n",
    "    target=target,\n",
    "    device=device,\n",
    "    n_points=batch_size,\n",
    "    constant_properties=constant_properties,\n",
    "    validation=0.1,\n",
    "    tolerance=0.001,\n",
    "    patience=60,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09881591796875 0.008544921875 2.6047229766845703e-05 0.08123779296875\n",
      "    Finished batch 1, [0, ...,36000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 2, [36000, ...,72000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 3, [72000, ...,108000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 4, [108000, ...,144000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 5, [144000, ...,180000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 6, [180000, ...,216000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 7, [216000, ...,252000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 8, [252000, ...,288000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 9, [288000, ...,324000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 10, [324000, ...,360000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 11, [360000, ...,396000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 12, [396000, ...,432000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 13, [432000, ...,468000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 14, [468000, ...,504000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 15, [504000, ...,540000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 16, [540000, ...,576000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 17, [576000, ...,612000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 18, [612000, ...,648000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 19, [648000, ...,684000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 20, [684000, ...,720000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 21, [720000, ...,756000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 22, [756000, ...,792000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 23, [792000, ...,828000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 24, [828000, ...,864000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 25, [864000, ...,900000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 26, [900000, ...,936000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 27, [936000, ...,972000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 28, [972000, ...,1008000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 29, [1008000, ...,1044000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 30, [1044000, ...,1080000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 31, [1080000, ...,1116000] \n",
      "NaN detected in C_initial_pred\n",
      "NaN detected in self.loss_initial\n",
      "NaN detected in predicted_pde\n",
      "NaN detected in self.loss_pde\n",
      "NaN detected in C_pred\n",
      "nan nan nan nan\n",
      "⚠ NaN detected in loss\n",
      "❌ NaN detected in gradients of 0.weight\n",
      "❌ NaN detected in gradients of 0.bias\n",
      "❌ NaN detected in gradients of 2.weight\n",
      "❌ NaN detected in gradients of 2.bias\n",
      "❌ NaN detected in gradients of 4.weight\n",
      "❌ NaN detected in gradients of 4.bias\n",
      "❌ NaN detected in gradients of 6.weight\n",
      "❌ NaN detected in gradients of 6.bias\n",
      "❌ NaN detected in gradients of 8.weight\n",
      "❌ NaN detected in gradients of 8.bias\n",
      "    Finished batch 32, [1116000, ...,1152000] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m (\n\u001b[1;32m      2\u001b[0m     model,\n\u001b[1;32m      3\u001b[0m     C_pde_loss_it,\n\u001b[1;32m      4\u001b[0m     C_boundary_loss_it,\n\u001b[1;32m      5\u001b[0m     C_initial_loss_it,\n\u001b[1;32m      6\u001b[0m     C_data_loss_it,\n\u001b[1;32m      7\u001b[0m     val_loss_it,\n\u001b[0;32m----> 8\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 323\u001b[0m, in \u001b[0;36mtrain.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    320\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 323\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(loss)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠ NaN detected in loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 136\u001b[0m, in \u001b[0;36mtrain.loss_func\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_func\u001b[39m(\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    122\u001b[0m ):\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    124\u001b[0m         [\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m         dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    134\u001b[0m     )[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, :]\n\u001b[0;32m--> 136\u001b[0m     C_initial_batch \u001b[38;5;241m=\u001b[39m \u001b[43minitial_condition_points\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# Computing intial loss\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     t_initial \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16)\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    141\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "(\n",
    "    model,\n",
    "    C_pde_loss_it,\n",
    "    C_boundary_loss_it,\n",
    "    C_initial_loss_it,\n",
    "    C_data_loss_it,\n",
    "    val_loss_it,\n",
    ") = trainer.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=[18, 9])\n",
    "\n",
    "fig.suptitle(\"Curva de aprendizagem\", fontsize=16)\n",
    "\n",
    "# Plotango 3D\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.set_xlabel(\"iterações\")\n",
    "ax.set_ylabel(\"perda\")\n",
    "ax.plot(\n",
    "    range(len(C_pde_loss_it.cpu().numpy())),\n",
    "    C_pde_loss_it.cpu().numpy(),\n",
    "    label=\"PDE loss\",\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    range(len(C_boundary_loss_it.cpu().numpy())),\n",
    "    C_boundary_loss_it.cpu().numpy(),\n",
    "    label=\"Boundary loss\",\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    range(len(val_loss_it.cpu().numpy())),\n",
    "    val_loss_it.cpu().numpy(),\n",
    "    label=\"Validation loss\",\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    range(len(C_data_loss_it.cpu().numpy())),\n",
    "    C_data_loss_it.cpu().numpy(),\n",
    "    label=\"Data loss\",\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    range(len(C_initial_loss_it.cpu().numpy())),\n",
    "    C_initial_loss_it.cpu().numpy(),\n",
    "    label=\"Initial loss\",\n",
    ")\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=[18, 9])\n",
    "\n",
    "fig.suptitle(\"Curva de aprendizagem\", fontsize=16)\n",
    "\n",
    "# Plotango 3D\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.set_xlabel(\"iterações\")\n",
    "ax.set_ylabel(\"perda\")\n",
    "\n",
    "ax.plot(\n",
    "    range(len(C_initial_loss_it.cpu().numpy())),\n",
    "    C_initial_loss_it.cpu().numpy()\n",
    "    + C_pde_loss_it.cpu().numpy()\n",
    "    + C_boundary_loss_it.cpu().numpy()\n",
    "    + C_data_loss_it.cpu().numpy(),\n",
    "    label=\"PINN loss\",\n",
    ")\n",
    "ax.plot(\n",
    "    range(len(val_loss_it.cpu().numpy())),\n",
    "    val_loss_it.cpu().numpy(),\n",
    "    label=\"Validation loss\",\n",
    ")\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "0.weight \t torch.Size([32, 7])\n",
      "0.bias \t torch.Size([32])\n",
      "2.weight \t torch.Size([32, 32])\n",
      "2.bias \t torch.Size([32])\n",
      "4.weight \t torch.Size([32, 32])\n",
      "4.bias \t torch.Size([32])\n",
      "6.weight \t torch.Size([32, 32])\n",
      "6.bias \t torch.Size([32])\n",
      "8.weight \t torch.Size([2, 32])\n",
      "8.bias \t torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "torch.save(model.state_dict(), cwd + \"/nn_parameters/\" + arch_str + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=7, out_features=32, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (3): Tanh()\n",
       "  (4): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (5): Tanh()\n",
       "  (6): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (7): GELU(approximate='none')\n",
       "  (8): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "model = generate_model(arch_str).to(device)\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(cwd + \"/nn_parameters/\" + arch_str + \".pt\", weights_only=True)\n",
    ")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Signature mismatch: 21 argument types given, but function takes 25 arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m Cb_final_device \u001b[38;5;241m=\u001b[39m cuda\u001b[38;5;241m.\u001b[39mto_device(np\u001b[38;5;241m.\u001b[39mzeros((size_t, size_x, size_y)))\n\u001b[1;32m     30\u001b[0m Cn_final_device \u001b[38;5;241m=\u001b[39m cuda\u001b[38;5;241m.\u001b[39mto_device(np\u001b[38;5;241m.\u001b[39mzeros((size_t, size_x, size_y)))\n\u001b[0;32m---> 32\u001b[0m \u001b[43mcu_solve_pde\u001b[49m\u001b[43m[\u001b[49m\u001b[43mthreadsperblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblockspergrid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCb_buf_0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCn_buf_0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCb_buf_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCn_buf_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCb_final_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCn_final_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambd_nb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmi_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambd_bn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCn_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_nb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m Cb_host \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(shape\u001b[38;5;241m=\u001b[39mCb_final_device\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mCb_final_device\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     57\u001b[0m Cb_final_device\u001b[38;5;241m.\u001b[39mcopy_to_host(Cb_host)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/cuda/dispatcher.py:539\u001b[0m, in \u001b[0;36m_LaunchConfiguration.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgriddim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblockdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msharedmem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/cuda/dispatcher.py:681\u001b[0m, in \u001b[0;36mCUDADispatcher.call\u001b[0;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[1;32m    679\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverloads\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 681\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m \u001b[43m_dispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    683\u001b[0m kernel\u001b[38;5;241m.\u001b[39mlaunch(args, griddim, blockdim, stream, sharedmem)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/cuda/dispatcher.py:689\u001b[0m, in \u001b[0;36mCUDADispatcher._compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kws\n\u001b[1;32m    688\u001b[0m argtypes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtypeof_pyval(a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m--> 689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margtypes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/cuda/dispatcher.py:932\u001b[0m, in \u001b[0;36mCUDADispatcher.compile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_compile:\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompilation disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 932\u001b[0m kernel \u001b[38;5;241m=\u001b[39m \u001b[43m_Kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpy_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargetoptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m# We call bind to force codegen, so that there is a cubin to cache\u001b[39;00m\n\u001b[1;32m    934\u001b[0m kernel\u001b[38;5;241m.\u001b[39mbind()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/core/compiler_lock.py:35\u001b[0m, in \u001b[0;36m_CompilerLock.__call__.<locals>._acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire_compile_lock\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m---> 35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/cuda/dispatcher.py:83\u001b[0m, in \u001b[0;36m_Kernel.__init__\u001b[0;34m(self, py_func, argtypes, link, debug, lineinfo, inline, fastmath, extensions, max_registers, opt, device)\u001b[0m\n\u001b[1;32m     77\u001b[0m nvvm_options \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfastmath\u001b[39m\u001b[38;5;124m'\u001b[39m: fastmath,\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopt\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m opt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     80\u001b[0m }\n\u001b[1;32m     82\u001b[0m cc \u001b[38;5;241m=\u001b[39m get_current_device()\u001b[38;5;241m.\u001b[39mcompute_capability\n\u001b[0;32m---> 83\u001b[0m cres \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_cuda\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpy_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvoid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mlineinfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineinfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfastmath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfastmath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnvvm_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnvvm_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m tgt_ctx \u001b[38;5;241m=\u001b[39m cres\u001b[38;5;241m.\u001b[39mtarget_context\n\u001b[1;32m     91\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpy_func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__code__\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/core/compiler_lock.py:35\u001b[0m, in \u001b[0;36m_CompilerLock.__call__.<locals>._acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire_compile_lock\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m---> 35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/cuda/compiler.py:196\u001b[0m, in \u001b[0;36mcompile_cuda\u001b[0;34m(pyfunc, return_type, args, debug, lineinfo, inline, fastmath, nvvm_options, cc)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtarget_extension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m target_override\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m target_override(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 196\u001b[0m     cres \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_extra\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtypingctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypingctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtargetctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtargetctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mpipeline_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCUDACompiler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m library \u001b[38;5;241m=\u001b[39m cres\u001b[38;5;241m.\u001b[39mlibrary\n\u001b[1;32m    206\u001b[0m library\u001b[38;5;241m.\u001b[39mfinalize()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/core/compiler.py:744\u001b[0m, in \u001b[0;36mcompile_extra\u001b[0;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compiler entry point\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03mParameter\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03m    compiler pipeline\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    742\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m pipeline_class(typingctx, targetctx, library,\n\u001b[1;32m    743\u001b[0m                           args, return_type, flags, \u001b[38;5;28mlocals\u001b[39m)\n\u001b[0;32m--> 744\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_extra\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/core/compiler.py:438\u001b[0m, in \u001b[0;36mCompilerBase.compile_extra\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mlifted \u001b[38;5;241m=\u001b[39m ()\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mlifted_from \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_bytecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/core/compiler.py:506\u001b[0m, in \u001b[0;36mCompilerBase._compile_bytecode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;124;03mPopulate and run pipeline for bytecode input\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfunc_ir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/core/compiler.py:481\u001b[0m, in \u001b[0;36mCompilerBase._compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (utils\u001b[38;5;241m.\u001b[39muse_new_style_errors() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(e, errors\u001b[38;5;241m.\u001b[39mNumbaError)):\n\u001b[0;32m--> 481\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mfail_reason \u001b[38;5;241m=\u001b[39m e\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_final_pipeline:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/core/compiler.py:472\u001b[0m, in \u001b[0;36mCompilerBase._compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    470\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 472\u001b[0m     \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mcr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    474\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/core/compiler_machinery.py:364\u001b[0m, in \u001b[0;36mPassManager.run\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (utils\u001b[38;5;241m.\u001b[39muse_new_style_errors() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m\n\u001b[1;32m    363\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(e, errors\u001b[38;5;241m.\u001b[39mNumbaError)):\n\u001b[0;32m--> 364\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    365\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m mode pipeline (step: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \\\n\u001b[1;32m    366\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_name, pass_desc)\n\u001b[1;32m    367\u001b[0m     patched_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_patch_error(msg, e)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/core/compiler_machinery.py:356\u001b[0m, in \u001b[0;36mPassManager.run\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    354\u001b[0m pass_inst \u001b[38;5;241m=\u001b[39m _pass_registry\u001b[38;5;241m.\u001b[39mget(pss)\u001b[38;5;241m.\u001b[39mpass_inst\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pass_inst, CompilerPass):\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_runPass\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_inst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLegacy pass in use\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/core/compiler_lock.py:35\u001b[0m, in \u001b[0;36m_CompilerLock.__call__.<locals>._acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire_compile_lock\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m---> 35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/core/compiler_machinery.py:311\u001b[0m, in \u001b[0;36mPassManager._runPass\u001b[0;34m(self, index, pss, internal_state)\u001b[0m\n\u001b[1;32m    309\u001b[0m     mutated \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m check(pss\u001b[38;5;241m.\u001b[39mrun_initialization, internal_state)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SimpleTimer() \u001b[38;5;28;01mas\u001b[39;00m pass_time:\n\u001b[0;32m--> 311\u001b[0m     mutated \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternal_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SimpleTimer() \u001b[38;5;28;01mas\u001b[39;00m finalize_time:\n\u001b[1;32m    313\u001b[0m     mutated \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m check(pss\u001b[38;5;241m.\u001b[39mrun_finalizer, internal_state)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/core/compiler_machinery.py:273\u001b[0m, in \u001b[0;36mPassManager._runPass.<locals>.check\u001b[0;34m(func, compiler_state)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck\u001b[39m(func, compiler_state):\n\u001b[0;32m--> 273\u001b[0m     mangled \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompiler_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mangled \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    275\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompilerPass implementations should return True/False. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompilerPass with name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m did not.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-numba/lib/python3.12/site-packages/numba/core/untyped_passes.py:125\u001b[0m, in \u001b[0;36mFixupArgs.run_pass\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    123\u001b[0m     state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (types\u001b[38;5;241m.\u001b[39mpyobject,) \u001b[38;5;241m*\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnargs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m!=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnargs\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSignature mismatch: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m argument types given, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut function takes \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m arguments\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m                     \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m]), state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnargs\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Signature mismatch: 21 argument types given, but function takes 25 arguments"
     ]
    }
   ],
   "source": [
    "from fvm_model_parallel import cu_solve_pde\n",
    "import math\n",
    "from numba import cuda\n",
    "\n",
    "speed_up = []\n",
    "\n",
    "for i in range(33):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Definindo número de threads e blocos para cuda\n",
    "\n",
    "    threadsperblock = (size_x, size_y)\n",
    "    blockspergrid_x = math.ceil(size_x / threadsperblock[0])\n",
    "    blockspergrid_y = math.ceil(size_y / threadsperblock[1])\n",
    "    blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "\n",
    "    # Inicializando as matrizes para concentrações de neutrófilos (Cn) e bactérias (Cb)\n",
    "\n",
    "    Cb_buf_0 = cuda.to_device(np.zeros((size_x, size_y)))\n",
    "    Cn_buf_0 = cuda.to_device(np.zeros((size_x, size_y)))\n",
    "\n",
    "    # This extra array is used for synchronization purposes\n",
    "\n",
    "    Cb_buf_1 = cuda.device_array_like(Cb_buf_0)\n",
    "    Cn_buf_1 = cuda.device_array_like(Cn_buf_0)\n",
    "\n",
    "    # Matrizes para armazenar as concentrações em cada passo de tempo\n",
    "    Cb_final_device = cuda.to_device(np.zeros((size_t, size_x, size_y)))\n",
    "    Cn_final_device = cuda.to_device(np.zeros((size_t, size_x, size_y)))\n",
    "\n",
    "    cu_solve_pde[threadsperblock, blockspergrid](\n",
    "        Cb_buf_0,\n",
    "        Cn_buf_0,\n",
    "        Cb_buf_1,\n",
    "        Cn_buf_1,\n",
    "        Cb_final_device,\n",
    "        Cn_final_device,\n",
    "        size_t,\n",
    "        size_x,\n",
    "        size_y,\n",
    "        h,\n",
    "        k,\n",
    "        Db,\n",
    "        Dn,\n",
    "        phi,\n",
    "        cb,\n",
    "        lambd_nb,\n",
    "        mi_n,\n",
    "        lambd_bn,\n",
    "        y_n,\n",
    "        Cn_max,\n",
    "        X_nb,\n",
    "    )\n",
    "\n",
    "    Cb_host = np.empty(shape=Cb_final_device.shape, dtype=Cb_final_device.dtype)\n",
    "    Cb_final_device.copy_to_host(Cb_host)\n",
    "\n",
    "    Cn_host = np.empty(shape=Cn_final_device.shape, dtype=Cn_final_device.dtype)\n",
    "    Cn_final_device.copy_to_host(Cn_host)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    cuda_time = end - start\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    mesh = torch.cat([t_tc, x_tc, y_tc], dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Cl_pinn_device, Cp_pinn_device = model(mesh).split(1, dim=1)\n",
    "\n",
    "    Cl_pinn = Cl_pinn_device.cpu().detach().numpy()\n",
    "    Cp_pinn = Cp_pinn_device.cpu().detach().numpy()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    pinn_time = end - start\n",
    "\n",
    "    speed_up.append(cuda_time / pinn_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_speed_up = np.mean(speed_up)\n",
    "std_speed_up = np.std(speed_up)\n",
    "\n",
    "rmse = np.mean(\n",
    "    [\n",
    "        ((Cl_p[0] - Cl_f) ** 2 + (Cp_p[0] - Cp_f) ** 2) ** 0.5\n",
    "        for Cl_p, Cp_p, Cl_f, Cp_f in zip(\n",
    "            Cl_pinn, Cp_pinn, Cn_fdm.flatten(), Cb_fdm.flatten()\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "max_ae = np.max(\n",
    "    [\n",
    "        [((Cl_p[0] - Cl_f) ** 2) ** 0.5, ((Cp_p[0] - Cp_f) ** 2) ** 0.5]\n",
    "        for Cl_p, Cp_p, Cl_f, Cp_f in zip(\n",
    "            Cl_pinn, Cp_pinn, Cn_fdm.flatten(), Cb_fdm.flatten()\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    \"rmse\": rmse,\n",
    "    \"max_ae\": max_ae,\n",
    "    \"mean_speed_up\": mean_speed_up,\n",
    "    \"std_speed_up\": std_speed_up,\n",
    "    \"Cl_pinn\": Cl_pinn,\n",
    "    \"Cp_pinn\": Cp_pinn,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erro absoluto médio\", rmse)\n",
    "print(\"Erro absoluto máximo\", max_ae)\n",
    "print(\"Speed Up: {} +/-{}\".format(mean_speed_up, std_speed_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cl_pinn_np = Cl_pinn.reshape(size_t, size_x, size_y)\n",
    "Cp_pinn_np = Cp_pinn.reshape(size_t, size_x, size_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(x_dom[0], x_dom[1], num=size_x, endpoint=True)\n",
    "y = np.linspace(y_dom[0], y_dom[1], num=size_y, endpoint=True)\n",
    "t = np.linspace(t_dom[0], t_dom[1], num=size_t, endpoint=True)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "time_plot = np.linspace(0, len(t) - 1, num=5, endpoint=True, dtype=int)\n",
    "\n",
    "fig = plt.figure(figsize=[6 * len(time_plot), 14])\n",
    "\n",
    "fig.suptitle(\"Resposta imunológica a patógenos\", fontsize=16)\n",
    "\n",
    "for i, time_inst in enumerate(time_plot):\n",
    "    # Plotango 3D\n",
    "    ax = fig.add_subplot(4, len(time_plot), i + 1)\n",
    "\n",
    "    vmin = np.min(Cp_pinn_np)\n",
    "    vmax = np.max(Cp_pinn_np)\n",
    "\n",
    "    contour = ax.contourf(\n",
    "        X,\n",
    "        Y,\n",
    "        Cp_pinn_np[time_inst],\n",
    "        cmap=\"jet\",\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Con. de bactérias em t={}\".format(t[time_inst]))\n",
    "    ax.set_xlabel(\"tempo\")\n",
    "    ax.set_ylabel(\"cond. inicial\")\n",
    "    colobar = fig.colorbar(contour, ticks=np.linspace(vmin, vmax, num=5))\n",
    "\n",
    "for i, time_inst in enumerate(time_plot):\n",
    "    # Plotango 3D\n",
    "    ax = fig.add_subplot(4, len(time_plot), i + len(time_plot) + 1)\n",
    "\n",
    "    vmin = np.min(Cl_pinn_np)\n",
    "    vmax = np.max(Cl_pinn_np)\n",
    "\n",
    "    contour = ax.contourf(\n",
    "        X,\n",
    "        Y,\n",
    "        Cl_pinn_np[time_inst],\n",
    "        cmap=\"jet\",\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Con. de bactérias em t={}\".format(t[time_inst]))\n",
    "    ax.set_xlabel(\"tempo\")\n",
    "    ax.set_ylabel(\"cond. inicial\")\n",
    "    colobar = fig.colorbar(contour, ticks=np.linspace(vmin, vmax, num=5))\n",
    "\n",
    "for i, it in enumerate(time_plot):\n",
    "    # Plotango 3D\n",
    "    ax = fig.add_subplot(4, len(time_plot), i + len(time_plot) * 2 + 1)\n",
    "\n",
    "    vmin = np.min(Cb_fdm)\n",
    "    vmax = np.max(Cb_fdm)\n",
    "\n",
    "    contour = ax.contourf(\n",
    "        X,\n",
    "        Y,\n",
    "        Cb_fdm[it],\n",
    "        cmap=\"jet\",\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Con. de bactérias em t={}\".format(t[it]))\n",
    "    ax.set_xlabel(\"tempo\")\n",
    "    ax.set_ylabel(\"cond. inicial\")\n",
    "    colobar = fig.colorbar(contour, ticks=np.linspace(vmin, vmax, num=5))\n",
    "\n",
    "for i, it in enumerate(time_plot):\n",
    "    # Plotango 3D\n",
    "    ax = fig.add_subplot(4, len(time_plot), i + len(time_plot) * 3 + 1)\n",
    "\n",
    "    vmin = np.min(Cn_fdm)\n",
    "    vmax = np.max(Cn_fdm)\n",
    "\n",
    "    contour = ax.contourf(\n",
    "        X,\n",
    "        Y,\n",
    "        Cn_fdm[it],\n",
    "        cmap=\"jet\",\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Con. de bactérias em t={}\".format(t[it]))\n",
    "    ax.set_xlabel(\"tempo\")\n",
    "    ax.set_ylabel(\"cond. inicial\")\n",
    "    colobar = fig.colorbar(contour, ticks=np.linspace(vmin, vmax, num=5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-numba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
